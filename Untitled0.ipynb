{
 "metadata": {
  "name": "Untitled0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, os.path\n",
      "import sys\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "sys.path.append('/home/will/PatientPicker/')\n",
      "sys.path.append('/home/will/PySeqUtils/')\n",
      "import LoadingTools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "redcap_data = LoadingTools.load_redcap_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_months(dt):\n",
      "    \n",
      "    return dt.astype('timedelta64[D]')/np.timedelta64(1, 'D')/30\n",
      "\n",
      "date_data = redcap_data[['Patient ID', 'VisitNum','Date Of Visit']]\n",
      "l = []\n",
      "for tup in pat_joins:\n",
      "    \n",
      "    for pat in tup:\n",
      "        mask = date_data['Patient ID'] == pat\n",
      "        tmp = date_data[mask].copy()\n",
      "        tmp.sort('VisitNum')\n",
      "        tmp['Date'] = pd.to_datetime(tmp['Date Of Visit'], coerce = True)\n",
      "        tmp = tmp.drop(['Date Of Visit'], axis = 1)\n",
      "        try:\n",
      "            tmp['Months from R00'] = (tmp['Date'] - tmp['Date'].iloc[0]).map(get_months)\n",
      "        except IndexError:\n",
      "            pass\n",
      "        l.append(tmp.copy())\n",
      "    \n",
      "    \n",
      "extra_res = pd.concat(l, axis = 0, ignore_index = True)\n",
      "extra_res.to_excel('/home/will/Downloads/joining_patients.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat_joins = [('A0138', 'A0360'),\n",
      "             ('A0017', 'A0054'),\n",
      "             ('A0418', 'A0423'),\n",
      "             ('A0234', 'A0266'),\n",
      "             ('A0410', 'A0424'),\n",
      "             ('A0082', 'A0346'),\n",
      "             ('A0077', 'A0370'),\n",
      "             ('A0098', 'A0126'),\n",
      "             ('A0023', 'A0114'),\n",
      "             ('A0131', 'A0157'),\n",
      "             ('A0059', 'A0403'),\n",
      "             ('A0016', 'A0053'),\n",
      "             ('A0219', 'A0442')]\n",
      "#pat_index = redcap_data['Patient ID']\n",
      "#orig = pat_index.copy()\n",
      "#for joins in pat_joins:\n",
      "#    base_pat = joins[0]\n",
      "#    for join_pat in joins[1:]:\n",
      "#        print base_pat, join_pat, (pat_index == join_pat).sum()\n",
      "#        pat_index[pat_index == join_pat] = base_pat\n",
      "#(orig != pat_index).sum()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "ld = []\n",
      "for f in glob.glob('/home/will/SubCData/LANLRes/LANLResults_*.txt'):\n",
      "    print f\n",
      "    ld.append(pd.read_csv(f, sep='\\t', index_col=0))\n",
      "print 'concating'    \n",
      "lanl_data = pd.concat(ld, axis = 0, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/will/SubCData/LANLRes/LANLResults_SubB_pre2000.txt\n",
        "/home/will/SubCData/LANLRes/LANLResults_SubC.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_F.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_M.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_SubB_post2000.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_O.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "concating"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from types import StringType\n",
      "def norm_id(inser):\n",
      "    \n",
      "    cols = ['Accession', 'GI number']\n",
      "    for col in cols:\n",
      "        if type(inser[col]) == StringType:\n",
      "            return inser[col].split('.')[0]\n",
      "    print inser\n",
      "    raise KeyboardInterrupt\n",
      "    \n",
      "\n",
      "lanl_data['GBid'] = lanl_data.apply(norm_id, axis = 1)\n",
      "agg_lanl_data = lanl_data.groupby('GBid').first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "from Bio import SeqIO\n",
      "from concurrent.futures import ProcessPoolExecutor\n",
      "from itertools import islice, imap\n",
      "import os, os.path\n",
      "import csv\n",
      "\n",
      "def get_gi_acc(fname):\n",
      "    gb = fname.split('/')[-1].split('.')[0]\n",
      "    with open(fname) as handle:\n",
      "        for line in handle:\n",
      "            if line.startswith('ACCESSION'):\n",
      "                acc = line.strip().split()[-1]\n",
      "                return gb, acc\n",
      "    raise AssertionError\n",
      "\n",
      "\n",
      "\n",
      "gi_to_acc_dict = {}\n",
      "\n",
      "fname = '/home/will/WLAHDB_data/gi_to_acc.csv'\n",
      "if os.path.exists(fname):\n",
      "    with open(fname) as handle:\n",
      "        for row in csv.reader(handle):\n",
      "            gi_to_acc_dict[row[0]] = row[1]\n",
      "else:\n",
      "    gb_files = glob.glob('/home/will/WLAHDB_data/GenbankDL/*.gb')\n",
      "    with open(fname, 'w') as handle:\n",
      "        writer = csv.writer(handle)\n",
      "        for num, (gbm, acc) in enumerate(imap(get_gi_acc, gb_files)):\n",
      "            if (num == 100) or (num % 50000 == 0):\n",
      "                print num\n",
      "            gi_to_acc_dict[gbm] = acc\n",
      "            writer.writerow((gbm, acc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import GeneralSeqTools\n",
      "files = [('C', sorted(glob.glob('/home/will/WLAHDB_data/SeqDump/C_*'))),\n",
      "         ('B', sorted(glob.glob('/home/will/WLAHDB_data/SeqDump/B_*')))]\n",
      "seqs = []\n",
      "for sub, sfiles in files:\n",
      "    for f in sfiles:\n",
      "        with open(f) as handle:\n",
      "            base_name = f.rsplit(os.sep,1)[1].rsplit('.',1)[0]\n",
      "            prot = base_name.split('_')[1]\n",
      "            for name, seq in GeneralSeqTools.fasta_reader(handle):\n",
      "                seqs.append({\n",
      "                             'Seq':seq,\n",
      "                             'ID':gi_to_acc_dict[name],\n",
      "                             'Prot':prot,\n",
      "                             'Subtype':sub\n",
      "                             })\n",
      "            \n",
      "seqdf = pd.DataFrame(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seqdf['HasSeq'] = 1.0\n",
      "cols = ['CD4 count', 'Viral load']\n",
      "seq_counts = pd.pivot_table(seqdf,\n",
      "                            rows = ['Subtype', 'ID'],\n",
      "                            cols = 'Prot',\n",
      "                            values = 'HasSeq',\n",
      "                            aggfunc = 'sum')\n",
      "ex_data, seq_count_aln = agg_lanl_data[cols].align(seq_counts.ix['C'], axis = 0, join = 'right')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fourkb_cols = ['vpr', 'tat', 'vpu', 'env', 'ltr']\n",
      "\n",
      "ex_data['CD4'] = ex_data['CD4 count'].notnull()\n",
      "ex_data['VL'] = ex_data['Viral load'].notnull()\n",
      "ex_data['HasV3'] = seq_count_aln['v3'].notnull()\n",
      "ex_data['Has44'] = seq_count_aln[fourkb_cols].fillna(0).sum(axis = 1)==5\n",
      "\n",
      "for col in seq_count_aln.columns:\n",
      "    ex_data[col] = seq_count_aln[col].notnull()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ex_data[other_cols].sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "ID\n",
        "AB002978    1\n",
        "AB002981    1\n",
        "AB012987    1\n",
        "AB012990    1\n",
        "AB013119    1\n",
        "AB013123    1\n",
        "AB014776    1\n",
        "AB014780    1\n",
        "AB014783    1\n",
        "AB014789    1\n",
        "AB014793    1\n",
        "AB014794    1\n",
        "AB014813    1\n",
        "AB014819    1\n",
        "AB014825    1\n",
        "...\n",
        "Z76295    1\n",
        "Z76296    1\n",
        "Z76297    1\n",
        "Z76298    1\n",
        "Z76299    1\n",
        "Z76301    1\n",
        "Z76304    1\n",
        "Z76306    1\n",
        "Z76310    1\n",
        "Z76342    1\n",
        "Z76734    1\n",
        "Z92584    2\n",
        "Z95462    1\n",
        "Z95464    1\n",
        "Z98033    0\n",
        "Length: 46111, dtype: int64"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import product\n",
      "ncounts = []\n",
      "other_cols = ['CD4', 'VL', 'HasV3', 'Has44']\n",
      "for col, ocol in product(seq_count_aln.columns, other_cols+['ASeqs', '_All']):\n",
      "    if ocol == 'ASeqs':\n",
      "        ncounts.append({\n",
      "                    'Prot': col,\n",
      "                    'Col': ocol,\n",
      "                    'Count': ex_data[col].sum()\n",
      "                    })\n",
      "    elif ocol == '_All':\n",
      "        ncounts.append({\n",
      "                    'Prot': col,\n",
      "                    'Col': ocol,\n",
      "                    'Count': (ex_data[col]*(ex_data[other_cols].sum(axis=1)==4)).sum()\n",
      "                    })\n",
      "    else:\n",
      "        ncounts.append({\n",
      "                        'Prot': col,\n",
      "                        'Col': ocol,\n",
      "                        'Count': (ex_data[col]*ex_data[ocol]).sum()\n",
      "                        })\n",
      "table = pd.pivot_table(pd.DataFrame(ncounts),\n",
      "               rows = 'Prot',\n",
      "               cols = 'Col',\n",
      "               values = 'Count',\n",
      "               aggfunc = 'sum')\n",
      "table.to_excel('/home/will/Dropbox/Wigdahl HIV Lab/SubCAnalysis/new_count_table.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Col</th>\n",
        "      <th>ASeqs</th>\n",
        "      <th>CD4</th>\n",
        "      <th>Has44</th>\n",
        "      <th>HasV3</th>\n",
        "      <th>VL</th>\n",
        "      <th>_All</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Prot</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>env</th>\n",
        "      <td> 11834</td>\n",
        "      <td> 114</td>\n",
        "      <td> 268</td>\n",
        "      <td> 11823</td>\n",
        "      <td> 4429</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>gag</th>\n",
        "      <td>  7826</td>\n",
        "      <td> 136</td>\n",
        "      <td>  10</td>\n",
        "      <td>  2452</td>\n",
        "      <td>  724</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>gp120</th>\n",
        "      <td> 12620</td>\n",
        "      <td> 111</td>\n",
        "      <td> 262</td>\n",
        "      <td> 12610</td>\n",
        "      <td> 4412</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>gp41</th>\n",
        "      <td> 12423</td>\n",
        "      <td> 120</td>\n",
        "      <td> 268</td>\n",
        "      <td> 12225</td>\n",
        "      <td> 4648</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ltr</th>\n",
        "      <td>  3146</td>\n",
        "      <td> 120</td>\n",
        "      <td> 268</td>\n",
        "      <td>  2384</td>\n",
        "      <td>  909</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>nef</th>\n",
        "      <td>  4125</td>\n",
        "      <td> 173</td>\n",
        "      <td> 267</td>\n",
        "      <td>  2542</td>\n",
        "      <td>  869</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pol</th>\n",
        "      <td>  2236</td>\n",
        "      <td>  95</td>\n",
        "      <td>  10</td>\n",
        "      <td>  2201</td>\n",
        "      <td>  597</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>rev</th>\n",
        "      <td>  2223</td>\n",
        "      <td>  22</td>\n",
        "      <td>   0</td>\n",
        "      <td>  2197</td>\n",
        "      <td>  698</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tat</th>\n",
        "      <td>   854</td>\n",
        "      <td>   5</td>\n",
        "      <td> 268</td>\n",
        "      <td>   342</td>\n",
        "      <td>  135</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>v3</th>\n",
        "      <td> 37204</td>\n",
        "      <td> 123</td>\n",
        "      <td> 268</td>\n",
        "      <td> 37204</td>\n",
        "      <td> 6518</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>vif</th>\n",
        "      <td>  3564</td>\n",
        "      <td> 112</td>\n",
        "      <td> 263</td>\n",
        "      <td>  2931</td>\n",
        "      <td>  992</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>vpr</th>\n",
        "      <td>  3458</td>\n",
        "      <td> 111</td>\n",
        "      <td> 268</td>\n",
        "      <td>  2888</td>\n",
        "      <td>  951</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>vpu</th>\n",
        "      <td>  3796</td>\n",
        "      <td> 114</td>\n",
        "      <td> 268</td>\n",
        "      <td>  3144</td>\n",
        "      <td>  995</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "Col    ASeqs  CD4  Has44  HasV3    VL  _All\n",
        "Prot                                       \n",
        "env    11834  114    268  11823  4429     0\n",
        "gag     7826  136     10   2452   724     0\n",
        "gp120  12620  111    262  12610  4412     0\n",
        "gp41   12423  120    268  12225  4648     0\n",
        "ltr     3146  120    268   2384   909     0\n",
        "nef     4125  173    267   2542   869     0\n",
        "pol     2236   95     10   2201   597     0\n",
        "rev     2223   22      0   2197   698     0\n",
        "tat      854    5    268    342   135     0\n",
        "v3     37204  123    268  37204  6518     0\n",
        "vif     3564  112    263   2931   992     0\n",
        "vpr     3458  111    268   2888   951     0\n",
        "vpu     3796  114    268   3144   995     0"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_pvs = [('A0001','R02'),\n",
      "              ('A0004','R02'),('A0004','R07'),\n",
      "              ('A0023','R01'),('A0041','R02'),\n",
      "              ('A0046','R02'),('A0048','R02'),\n",
      "              ('A0052','R01'),('A0070','R01'),\n",
      "              ('A0071','R01'),('A0072','R01'),\n",
      "              ('A0107','R05'),('A0110','R02'),\n",
      "              ('A0111','R01'),('A0127','R01'),\n",
      "              ('A0128','R00'),('A0139','R00'),\n",
      "              ('A0143','R00'),('A0152','R00'),\n",
      "              ('A0164','R00'),('A0165','R00'),\n",
      "              ('A0172','R00'),('A0208','R00'),\n",
      "              ('A0213','R00'),('A0225','R00'),\n",
      "              ('A0252','R00'),('A0259','R00'),\n",
      "              ('A0278','R00'),('A0281','R00'),\n",
      "              ('A0310','R00'),('A0326','R00'),\n",
      "              ('A0365','R00'),('A0367','R05'),\n",
      "              ('A0377','R00'),('A0378','R00'),\n",
      "              ('A0396','R00'),('A0403','R01'),\n",
      "              ('A0421','R00')]\n",
      "\n",
      "col_order = ['Patient ID','VisitNum','Age','NumTotalVisits','Latest CD4 count','Current Alcohol Use',\n",
      "             'Current Tobacco Use','Days since baseline','Gender','Race','HAART','Hepatitis C status (HCV)',\n",
      "             'HIVD score','HIVD.I','Hepatitis B status (HBV)','Latest CD8 count','Nadir CD4 count',\n",
      "             'Nadir CD8 count','Peak viral load','Latest Viral load','Years Seropositive',\n",
      "             'TOSample.Benzodiazepines','TOSample.Cannabinoid','TOSample.Cocaine','TOSample.Opiates',\n",
      "             'ALL.Benzodiazepines','ALL.Cannabinoid','ALL.Cocaine','ALL.Opiates',\n",
      "             'ATSample.Amphetamines','ATSample.Barbiturates','ATSample.Benzodiazepines',\n",
      "             'ATSample.Cannabinoid','ATSample.Cocaine','ATSample.Opiates','ATSample.Phencyclidine']\n",
      "\n",
      "wanted_pvs = pd.DataFrame(wanted_pvs, columns = ['Patient ID', 'VisitNum'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_cols = [col for col in redcap_data.columns if col.startswith('Test-')]\n",
      "at_sample = redcap_data[test_cols].rename(dict([(col, col.replace('Test-', 'ATSample.'))]))\n",
      "to_sample = redcap_data.groupby(level = ['Patient ID'])[test_cols].transform(pd.expanding_mean).rename(dict([(col, col.replace('Test-', 'TOSample.'))]))\n",
      "all_sample = redcap_data.groupby(level = ['Patient ID'])[test_cols].transform(lambda x: x.mean()).rename(dict([(col, col.replace('Test-', 'ALL.'))]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mark_haart(inrow):\n",
      "    if inrow['HAART-Naive']:\n",
      "        return 'nH'\n",
      "    elif inrow['HAART-Non-Adherent']:\n",
      "        return 'dH'\n",
      "    elif inrow['HAART-Off']:\n",
      "        return 'dH'\n",
      "    elif inrow['HAART-On']:\n",
      "        return 'cH'\n",
      "    else:\n",
      "        return np.nan\n",
      "    \n",
      "    \n",
      "haart_cols = [col for col in redcap_data.columns if col.startswith('HAART')]\n",
      "haart_data = redcap_data.groupby(level = [0,1])[haart_cols].apply(mark_haart)\n",
      "num_data = redcap_data.groupby(level = [0])[['Age']].transform(len).rename(columns={'Age':'NumTotalVisits'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_impaired_call(val):\n",
      "    if val < 10:\n",
      "        return 'Impaired'\n",
      "    elif val >= 10:\n",
      "        return 'Not Impaired'\n",
      "    else:\n",
      "        return np.nan\n",
      "\n",
      "hivd_data = pd.DataFrame({'HIVD score':redcap_data['TMHDS'],\n",
      "                          'HIVD.I':redcap_data['TMHDS'].map(make_impaired_call)})\n",
      "days_data = redcap_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rename_dict = {'Latest CD4 count (cells/uL)':'Latest CD4 count',\n",
      "               'Latest viral load': 'Latest Viral load',\n",
      "               'Latest CD8 count (cells/uL)':'Latest CD8 count',\n",
      "               'Nadir CD4 count (cells/uL)':'Nadir CD4 count',\n",
      "               'Nadir CD4 count (cells/uL)':'Nadir CD8 count',\n",
      "               'Peak viral load (copies/mL)':'Peak viral load',\n",
      "               }\n",
      "outredcap = pd.concat([redcap_data.rename(columns=rename_dict), at_sample, to_sample, all_sample, num_data,\n",
      "                       pd.DataFrame({'HAART':haart_data}), hivd_data], \n",
      "                      axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outredcap[col_order[2:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'Days since baseline not in index'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-89-182132bdaeea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutredcap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_order\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1919\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1922\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1951\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1952\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1953\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1954\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis)\u001b[0m\n\u001b[0;32m    574\u001b[0m                             \u001b[0mto_or\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__eq__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto_or\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m                             \u001b[0mmask\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mto_or\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'Days since baseline not in index'"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.rolling_mean?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}