{
 "metadata": {
  "name": "HIVTransTool"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Seq\n",
      "from Bio import SeqIO\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sys\n",
      "import os\n",
      "sys.path.append('/home/will/PySeqUtils/')\n",
      "from GeneralSeqTools import fasta_reader, fasta_writer\n",
      "from HIVAlignTools import SeqTransformer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shlex\n",
      "from subprocess import check_call\n",
      "\n",
      "def score_seq(known, guess, gapopen=10, gapextend=1):\n",
      "    \n",
      "    cmd = 'needle -asequence %(cb)s -bsequence %(seq)s -aformat score -gapopen %(go)f -gapextend %(ge)s -outfile %(out)s'\n",
      "    with NamedTemporaryFile() as conb_handle:\n",
      "        fasta_writer(conb_handle, [('SeqA', known)])\n",
      "        conb_handle.flush()\n",
      "        os.fsync(conb_handle.fileno())\n",
      "        with NamedTemporaryFile() as seq_handle:\n",
      "            fasta_writer(seq_handle, [('Seq1', guess)])\n",
      "            seq_handle.flush()\n",
      "            os.fsync(seq_handle.fileno())\n",
      "            with NamedTemporaryFile() as out_handle:\n",
      "                param_dict = {\n",
      "                              'cb':conb_handle.name,\n",
      "                              'seq':seq_handle.name,\n",
      "                              'out':out_handle.name,\n",
      "                              'go':gapopen,\n",
      "                              'ge':gapextend\n",
      "                              }\n",
      "                cmd_list = shlex.split(cmd % param_dict)\n",
      "                check_call(cmd_list)\n",
      "                for line in out_handle:\n",
      "                    parts = line.split()\n",
      "                    if (len(parts) == 4):\n",
      "                        return float(parts[-1][1:-2])\n",
      "    \n",
      "\n",
      "\n",
      "def score_seqs(known_seqs, guess_seqs, gapopen=10, gapextend=1):\n",
      "    \n",
      "    score = 0.0\n",
      "    for ind in range(known_seqs.shape[0]):\n",
      "        score += score_seq(known_seqs[0], guess_seqs[0],\n",
      "                           gapopen=gapopen, gapextend=gapextend)\n",
      "    return score\n",
      "\n",
      "\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.base import BaseEstimator, ClusterMixin\n",
      "from tempfile import NamedTemporaryFile\n",
      "from Bio.SubsMat import MatrixInfo as matlist\n",
      "from Bio.Blast import NCBIXML\n",
      "from StringIO import StringIO\n",
      "from Bio.Blast.Applications import NcbiblastxCommandline, NcbiblastnCommandline\n",
      "\n",
      "\n",
      "class BlastAligner(BaseEstimator, ClusterMixin):\n",
      "    \n",
      "    def __init__(self, evalue=10, word_size=2, gapopen=11, gapextend=1, \n",
      "                 max_intron_length = 20, tmp_path = '/tmp/', result_type = 'aa',\n",
      "                 db_path=NamedTemporaryFile(suffix='.fasta').name, num_threads=1):\n",
      "        self.evalue = evalue\n",
      "        self.word_size = word_size\n",
      "        self.gapopen = gapopen\n",
      "        self.gapextend = gapextend\n",
      "        self.max_intron_length = max_intron_length\n",
      "        self.tmp_path = tmp_path\n",
      "        self.result_type = result_type\n",
      "        self.db_path = db_path\n",
      "        self.num_threads = num_threads\n",
      "    \n",
      "    def _write_seqs(self, X, handle):\n",
      "        \n",
      "        seqs = []\n",
      "        for row in range(X.shape[0]):\n",
      "            seq = ''.join(X[row])\n",
      "            seqs.append(('Seq-%03i' % row, ''.join(l for l in seq if l.isalpha())))\n",
      "            \n",
      "        fasta_writer(handle, seqs)\n",
      "        handle.flush()\n",
      "        os.fsync(handle.fileno())\n",
      "    \n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        \n",
      "        \n",
      "        empty_mask = y == 'XX'\n",
      "        \n",
      "        with open(self.db_path, 'w') as handle:\n",
      "            self._write_seqs(y[~empty_mask], handle)\n",
      "        cmd = 'makeblastdb -in %s -dbtype ' % self.db_path\n",
      "        if self.result_type == 'aa':\n",
      "            cmd += 'prot'\n",
      "        else:\n",
      "            cmd += 'nucl'\n",
      "        \n",
      "        check_call(shlex.split(cmd))\n",
      "        \n",
      "        \n",
      "        return self\n",
      "   \n",
      "    \n",
      "    def predict(self, X):\n",
      "        \n",
      "        if self.result_type == 'aa':\n",
      "            blast_cmd = NcbiblastxCommandline\n",
      "        else:\n",
      "            blast_cmd = NcbiblastnCommandline\n",
      "        \n",
      "        \n",
      "        with NamedTemporaryFile(dir=self.tmp_path, delete=True) as fasta_handle:    \n",
      "            self._write_seqs(X, fasta_handle)\n",
      "            blastx_cline = blast_cmd(query=fasta_handle.name,\n",
      "                                     db = self.db_path, outfmt=5, \n",
      "                                     out = '-',\n",
      "                                     evalue=self.evalue,\n",
      "                                     word_size=self.word_size,\n",
      "                                     gapopen=self.gapopen,\n",
      "                                     gapextend=self.gapextend,\n",
      "                                     max_intron_length=self.max_intron_length,\n",
      "                                     num_threads=self.num_threads)\n",
      "            stdout, stderr = blastx_cline()\n",
      "        \n",
      "        blast_records = NCBIXML.parse(StringIO(stdout))\n",
      "        seqs = []\n",
      "        names = []\n",
      "        prots = []\n",
      "        for rec in blast_records:\n",
      "            for align in rec.alignments:\n",
      "                hsp = align.hsps[0]\n",
      "                prots.append({\n",
      "                              'ID':rec.query,\n",
      "                              'Seq':hsp.query\n",
      "                              })\n",
      "        blast_out = pd.DataFrame(prots).groupby('ID')['Seq'].first()\n",
      "        wanted_out = pd.DataFrame({\n",
      "                                   'ID':['Seq-%03i' % i for i in range(X.shape[0])],\n",
      "                                   'want_seq':[True]*X.shape[0],\n",
      "                                   }).groupby('ID')['want_seq'].first()\n",
      "        out, _ = blast_out.align(wanted_out, join='right')\n",
      "        \n",
      "        return SeqTransformer().transform(out.fillna('XX').values)\n",
      "    \n",
      "    def score(self, X, y):\n",
      "        \n",
      "        empty_mask = y == 'XX'\n",
      "        out_aligns = self.predict(X)\n",
      "        \n",
      "        pos_scores = score_seqs(y[~empty_mask], out_aligns[~empty_mask])\n",
      "        bad_scores = score_seqs(out_aligns[empty_mask], out_aligns[empty_mask])\n",
      "        return (pos_scores - bad_scores)/y.shape[0]\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neg_controls = {\n",
      "                'env':['gag', 'pol', 'vif', 'vpr', 'ltr'],\n",
      "                'gag':['ltr', 'vif', 'vpr', 'vpu', 'tat', 'rev', 'env'],\n",
      "                #'ltr':['gag', 'pol', 'vpr', 'vpu', 'env'],\n",
      "                'nef':['pol', 'gag', 'vpu', 'tat'],\n",
      "                'pol':['env', 'vpr', 'vpu', 'nef', 'rev', 'ltr'],\n",
      "                'rev':['ltr', 'gag', 'pol', 'vif', 'nef'],\n",
      "                'tat':['ltr', 'pol', 'vif', 'nef'],\n",
      "                'vif':['ltr', 'tat', 'vpu', 'rev', 'env', 'nef'],\n",
      "                'vpr':['ltr', 'gag', 'pol', 'rev', 'env', 'nef'],\n",
      "                'vpu':['ltr', 'gag', 'pol', 'vif', 'vpr', 'nef'],\n",
      "                }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_seq(prot_name, typ):\n",
      "    trans_path = '/home/will/PySeqUtils/TransToolStuff/'\n",
      "    tmp = 'HIV1_ALL_2012_%s_%s.fasta' % (prot_name.lower(), typ.upper())\n",
      "    with open(trans_path + tmp) as handle:\n",
      "        return SeqTransformer.get_from_fasta_handle(handle)\n",
      "\n",
      "\n",
      "pos_names, pos_X = get_seq('genome', 'DNA')\n",
      "env_names, env_y = get_seq('env', 'pro')\n",
      "neg_names = []\n",
      "neg_X = None\n",
      "for neg_prot in neg_controls['env']:\n",
      "    tnames, tx = get_seq(neg_prot, 'DNA')\n",
      "    neg_names += tnames\n",
      "    if neg_X is None:\n",
      "        neg_X = tx.copy()\n",
      "    else:\n",
      "        neg_X = np.concatenate((neg_X, tx))\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_X_ser = pd.Series(pos_X, index=pos_names)\n",
      "env_y_ser = pd.Series(env_y, index=env_names)\n",
      "\n",
      "X_ser, y_ser = pos_X_ser.align(env_y_ser, join='inner')\n",
      "X = X_ser.values\n",
      "y = y_ser.values\n",
      "in_env = set(env_names)\n",
      "neg_inds = [num for num, name in enumerate(neg_names) if name not in in_env]\n",
      "wneg_X = neg_X[neg_inds]\n",
      "wneg_y = np.array(['XX']*wneg_X.shape[0])\n",
      "\n",
      "print X.shape, y.shape, wneg_X.shape, wneg_y.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1984,) (1984,) (6782,) (6782,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xall = np.concatenate((X, wneg_X))\n",
      "yall = np.concatenate((y, wneg_y))\n",
      "\n",
      "yclass = yall == 'XX'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split, StratifiedKFold, cross_val_score, StratifiedShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "param_dict = {'evalue':np.logspace(-50, 10, 15)}\n",
      "\n",
      "cv = StratifiedShuffleSplit(yclass, test_size=50, train_size=100)\n",
      "aligner = BlastAligner()\n",
      "gd = GridSearchCV(aligner, param_dict, refit=False, cv=cv, verbose=5, n_jobs=20, pre_dispatch=150)\n",
      "gd.fit(Xall, yall)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "[joblib] Attempting to do parallel computingwithout protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect you main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-852d9cd4ba5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maligner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlastAligner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maligner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    705\u001b[0m                           \u001b[1;34m\" The params argument will be removed in 0.15.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                           DeprecationWarning)\n\u001b[1;32m--> 707\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                     self.scorer_, self.verbose, **self.fit_params)\n\u001b[1;32m--> 493\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m                 for train, test in cv)\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[0malready_forked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__JOBLIB_SPAWNED_PARALLEL__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m                     raise ImportError('[joblib] Attempting to do parallel computing'\n\u001b[0m\u001b[0;32m    481\u001b[0m                             \u001b[1;34m'without protecting your import on a system that does '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m                             \u001b[1;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: [joblib] Attempting to do parallel computingwithout protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect you main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.cross_validation import Bootstrap\n",
      "\n",
      "cv = Bootstrap(len(names), n_iter=10, test_size=0.7)\n",
      "\n",
      "param_grid = {'evalue':[0.1, 1, 10, 20], \n",
      "              'word_size':[2, 5, 10], \n",
      "              'max_intron_length':[-1,4000,8000]}\n",
      "\n",
      "grid_search = GridSearchCV(BlastXAligner(), param_grid,\n",
      "                           n_jobs=10, pre_dispatch=10,\n",
      "                            verbose=1).fit(X.reshape(-1, 1))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "'MRVKGIRKNYQHLWRWGTMLLGMLMICSAAEKLWVTVYYGVPVWKEATTTLFCASDAKAYDTEVHNVWATHACVPTDPNPQEVVLENVTENFNMWKNNMVEQMHEDIISLWDQSLKPCVKLTPLCVTLNCTDLMNATNTNTTIIYRWRGEIKNCSFNITTSIRDKVQKEYALFYKLDVVPIDNDNTSYRLISCNTSVITQACPKVSFEPIPIHYCAPAGFAILKCNDKKFNGTGPCTNVSTVQCTHGIRPVVSTQLLLNGSLAEEEVVIRSENFTDNAKTIIVQLNESVEINCTRPNNNTRKSIHIGPGRAFYTTGEIIGDIRQAHCNISRAKWNNTLKQIVKKLREQFGNKTIVFNQSSGGDPEIVMHSFNCGGEFFYCNTTQLFNSTWNGTWNNTEGNITLPCRIKQIINMWQEVGKAMYAPPIRGQIRCSSNITGLLLTRDGGNNETEIFRPGGGDMRDNWRSELYKYKVVKIEPLGVAPTKAKRRVVQREKRAVGIGAMFLGFLGAAGSTMGAASMTLTVQARQLLSGIVQQQNNLLRAIEAQQHLLQLTVWGIKQLQARVLAVERYLKDQQLLGIWGCSGKLICTTAVPWNASWSNKSLDEIWDNMTWMEWEREIDNYTSLIYTLIEESQNQQEKNEQELLELDKWASLWNWFDITNWLWYIKIFIMIVGGLVGLRIVFAVLSIVNRVRQGYSPLSFQTRLPAPRGPDRPEGIEEEGGERDRDRSGRLVDGFLALIWDDLRSLCLFSYHRLRDLLLIVTRIVELLGRRGWEVLKYWWNLLQYWSQELKNSAVSLLNATAIAVAEGTDRVIEVVQRACRAILHIPRRIRQGLERALL'"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}