{
 "metadata": {
  "name": "Untitled0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, os.path\n",
      "import sys\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "sys.path.append('/home/will/PatientPicker/')\n",
      "import LoadingTools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "redcap_data = LoadingTools.load_redcap_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_months(dt):\n",
      "    \n",
      "    return dt.astype('timedelta64[D]')/np.timedelta64(1, 'D')/30\n",
      "\n",
      "date_data = redcap_data[['Patient ID', 'VisitNum','Date Of Visit']]\n",
      "l = []\n",
      "for tup in pat_joins:\n",
      "    \n",
      "    for pat in tup:\n",
      "        mask = date_data['Patient ID'] == pat\n",
      "        tmp = date_data[mask].copy()\n",
      "        tmp.sort('VisitNum')\n",
      "        tmp['Date'] = pd.to_datetime(tmp['Date Of Visit'], coerce = True)\n",
      "        tmp = tmp.drop(['Date Of Visit'], axis = 1)\n",
      "        try:\n",
      "            tmp['Months from R00'] = (tmp['Date'] - tmp['Date'].iloc[0]).map(get_months)\n",
      "        except IndexError:\n",
      "            pass\n",
      "        l.append(tmp.copy())\n",
      "    \n",
      "    \n",
      "extra_res = pd.concat(l, axis = 0, ignore_index = True)\n",
      "extra_res.to_excel('/home/will/Downloads/joining_patients.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat_joins = [('A0138', 'A0360'),\n",
      "             ('A0017', 'A0054'),\n",
      "             ('A0418', 'A0423'),\n",
      "             ('A0234', 'A0266'),\n",
      "             ('A0410', 'A0424'),\n",
      "             ('A0082', 'A0346'),\n",
      "             ('A0077', 'A0370'),\n",
      "             ('A0098', 'A0126'),\n",
      "             ('A0023', 'A0114'),\n",
      "             ('A0131', 'A0157'),\n",
      "             ('A0059', 'A0403'),\n",
      "             ('A0016', 'A0053'),\n",
      "             ('A0219', 'A0442')]\n",
      "#pat_index = redcap_data['Patient ID']\n",
      "#orig = pat_index.copy()\n",
      "#for joins in pat_joins:\n",
      "#    base_pat = joins[0]\n",
      "#    for join_pat in joins[1:]:\n",
      "#        print base_pat, join_pat, (pat_index == join_pat).sum()\n",
      "#        pat_index[pat_index == join_pat] = base_pat\n",
      "#(orig != pat_index).sum()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "ld = []\n",
      "for f in glob.glob('/home/will/SubCData/LANLRes/LANLResults_*.txt'):\n",
      "    print f\n",
      "    ld.append(pd.read_csv(f, sep='\\t', index_col=0))\n",
      "    \n",
      "lanl_data = pd.concat(ld, axis = 0, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/will/SubCData/LANLRes/LANLResults_SubB_pre2000.txt\n",
        "/home/will/SubCData/LANLRes/LANLResults_SubC.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_F.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_M.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_SubB_post2000.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/will/SubCData/LANLRes/LANLResults_O.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from types import StringType\n",
      "def norm_id(inser):\n",
      "    \n",
      "    cols = ['Accession', 'GI number']\n",
      "    for col in cols:\n",
      "        if type(inser[col]) == StringType:\n",
      "            return inser[col].split('.')[0]\n",
      "    print inser\n",
      "    raise KeyboardInterrupt\n",
      "    \n",
      "\n",
      "lanl_data['GBid'] = lanl_data.apply(norm_id, axis = 1)\n",
      "agg_lanl_data = lanl_data.groupby('GBid').first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "from Bio import SeqIO\n",
      "from concurrent.futures import ProcessPoolExecutor\n",
      "from itertools import islice, imap\n",
      "import os, os.path\n",
      "import csv\n",
      "\n",
      "def get_gi_acc(fname):\n",
      "    gb = fname.split('/')[-1].split('.')[0]\n",
      "    with open(fname) as handle:\n",
      "        for line in handle:\n",
      "            if line.startswith('ACCESSION'):\n",
      "                acc = line.strip().split()[-1]\n",
      "                return gb, acc\n",
      "    raise AssertionError\n",
      "\n",
      "\n",
      "\n",
      "gi_to_acc_dict = {}\n",
      "\n",
      "fname = '/home/will/WLAHDB_data/gi_to_acc.csv'\n",
      "if os.path.exists(fname):\n",
      "    with open(fname) as handle:\n",
      "        for row in csv.reader(handle):\n",
      "            gi_to_acc_dict[row[0]] = row[1]\n",
      "else:\n",
      "    gb_files = glob.glob('/home/will/WLAHDB_data/GenbankDL/*.gb')\n",
      "    with open(fname, 'w') as handle:\n",
      "        writer = csv.writer(handle)\n",
      "        for num, (gbm, acc) in enumerate(imap(get_gi_acc, gb_files)):\n",
      "            if (num == 100) or (num % 50000 == 0):\n",
      "                print num\n",
      "            gi_to_acc_dict[gbm] = acc\n",
      "            writer.writerow((gbm, acc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = [('C', sorted(glob.glob('/home/will/WLAHDB_data/SeqDump/C_*'))),\n",
      "         ('B', sorted(glob.glob('/home/will/WLAHDB_data/SeqDump/B_*')))]\n",
      "seqs = []\n",
      "for sub, sfiles in files:\n",
      "    for f in sfiles:\n",
      "        with open(f) as handle:\n",
      "            base_name = f.rsplit(os.sep,1)[1].rsplit('.',1)[0]\n",
      "            prot = base_name.split('_')[1]\n",
      "            for name, seq in GeneralSeqTools.fasta_reader(handle):\n",
      "                seqs.append({\n",
      "                             'Seq':seq,\n",
      "                             'ID':gi_to_acc_dict[name],\n",
      "                             'Prot':prot,\n",
      "                             'Subtype':sub\n",
      "                             })\n",
      "            \n",
      "seqdf = pd.DataFrame(seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seqdf['HasSeq'] = 1.0\n",
      "seq_counts = pd.pivot_table(seqdf,\n",
      "                            rows = 'ID',\n",
      "                            cols = 'Prot',\n",
      "                            values = 'HasSeq',\n",
      "                            aggfunc = 'sum')\n",
      "ex_data, seq_count_aln = agg_lanl_data.align(seq_counts, axis = 0, join = 'inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_pvs = [('A0001','R02'),\n",
      "              ('A0004','R02'),('A0004','R07'),\n",
      "              ('A0023','R01'),('A0041','R02'),\n",
      "              ('A0046','R02'),('A0048','R02'),\n",
      "              ('A0052','R01'),('A0070','R01'),\n",
      "              ('A0071','R01'),('A0072','R01'),\n",
      "              ('A0107','R05'),('A0110','R02'),\n",
      "              ('A0111','R01'),('A0127','R01'),\n",
      "              ('A0128','R00'),('A0139','R00'),\n",
      "              ('A0143','R00'),('A0152','R00'),\n",
      "              ('A0164','R00'),('A0165','R00'),\n",
      "              ('A0172','R00'),('A0208','R00'),\n",
      "              ('A0213','R00'),('A0225','R00'),\n",
      "              ('A0252','R00'),('A0259','R00'),\n",
      "              ('A0278','R00'),('A0281','R00'),\n",
      "              ('A0310','R00'),('A0326','R00'),\n",
      "              ('A0365','R00'),('A0367','R05'),\n",
      "              ('A0377','R00'),('A0378','R00'),\n",
      "              ('A0396','R00'),('A0403','R01'),\n",
      "              ('A0421','R00')]\n",
      "\n",
      "col_order = ['Patient ID','VisitNum','Age','NumTotalVisits','Latest CD4 count','Current Alcohol Use',\n",
      "             'Current Tobacco Use','Days since baseline','Gender','Race','HAART','Hepatitis C status (HCV)',\n",
      "             'HIVD score','HIVD.I','Hepatitis B status (HBV)','Latest CD8 count','Nadir CD4 count',\n",
      "             'Nadir CD8 count','Peak viral load','Latest Viral load','Years Seropositive',\n",
      "             'TOSample.Benzodiazepines','TOSample.Cannabinoid','TOSample.Cocaine','TOSample.Opiates',\n",
      "             'ALL.Benzodiazepines','ALL.Cannabinoid','ALL.Cocaine','ALL.Opiates',\n",
      "             'ATSample.Amphetamines','ATSample.Barbiturates','ATSample.Benzodiazepines',\n",
      "             'ATSample.Cannabinoid','ATSample.Cocaine','ATSample.Opiates','ATSample.Phencyclidine']\n",
      "\n",
      "wanted_pvs = pd.DataFrame(wanted_pvs, columns = ['Patient ID', 'VisitNum'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_cols = [col for col in redcap_data.columns if col.startswith('Test-')]\n",
      "at_sample = redcap_data[test_cols].rename(dict([(col, col.replace('Test-', 'ATSample.'))]))\n",
      "to_sample = redcap_data.groupby(level = ['Patient ID'])[test_cols].transform(pd.expanding_mean).rename(dict([(col, col.replace('Test-', 'TOSample.'))]))\n",
      "all_sample = redcap_data.groupby(level = ['Patient ID'])[test_cols].transform(lambda x: x.mean()).rename(dict([(col, col.replace('Test-', 'ALL.'))]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mark_haart(inrow):\n",
      "    if inrow['HAART-Naive']:\n",
      "        return 'nH'\n",
      "    elif inrow['HAART-Non-Adherent']:\n",
      "        return 'dH'\n",
      "    elif inrow['HAART-Off']:\n",
      "        return 'dH'\n",
      "    elif inrow['HAART-On']:\n",
      "        return 'cH'\n",
      "    else:\n",
      "        return np.nan\n",
      "    \n",
      "    \n",
      "haart_cols = [col for col in redcap_data.columns if col.startswith('HAART')]\n",
      "haart_data = redcap_data.groupby(level = [0,1])[haart_cols].apply(mark_haart)\n",
      "num_data = redcap_data.groupby(level = [0])[['Age']].transform(len).rename(columns={'Age':'NumTotalVisits'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_impaired_call(val):\n",
      "    if val < 10:\n",
      "        return 'Impaired'\n",
      "    elif val >= 10:\n",
      "        return 'Not Impaired'\n",
      "    else:\n",
      "        return np.nan\n",
      "\n",
      "hivd_data = pd.DataFrame({'HIVD score':redcap_data['TMHDS'],\n",
      "                          'HIVD.I':redcap_data['TMHDS'].map(make_impaired_call)})\n",
      "days_data = redcap_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rename_dict = {'Latest CD4 count (cells/uL)':'Latest CD4 count',\n",
      "               'Latest viral load': 'Latest Viral load',\n",
      "               'Latest CD8 count (cells/uL)':'Latest CD8 count',\n",
      "               'Nadir CD4 count (cells/uL)':'Nadir CD4 count',\n",
      "               'Nadir CD4 count (cells/uL)':'Nadir CD8 count',\n",
      "               'Peak viral load (copies/mL)':'Peak viral load',\n",
      "               }\n",
      "outredcap = pd.concat([redcap_data.rename(columns=rename_dict), at_sample, to_sample, all_sample, num_data,\n",
      "                       pd.DataFrame({'HAART':haart_data}), hivd_data], \n",
      "                      axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outredcap[col_order[2:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'Days since baseline not in index'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-89-182132bdaeea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutredcap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_order\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1919\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1922\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1951\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1952\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1953\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1954\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis)\u001b[0m\n\u001b[0;32m    574\u001b[0m                             \u001b[0mto_or\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__eq__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto_or\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m                             \u001b[0mmask\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mto_or\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'Days since baseline not in index'"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.rolling_mean?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}