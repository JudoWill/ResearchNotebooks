{
 "metadata": {
  "name": "NewTreeFunctions"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame, Series, merge, read_csv, MultiIndex, Index, concat\n",
      "from subprocess import check_call\n",
      "from tempfile import NamedTemporaryFile as NTF\n",
      "import os, os.path\n",
      "import numpy as np\n",
      "from scipy.stats import ttest_ind\n",
      "from itertools import groupby,combinations, islice\n",
      "from operator import itemgetter\n",
      "from Bio import Phylo\n",
      "import networkx\n",
      "import sys\n",
      "\n",
      "from random import shuffle\n",
      "import csv, shlex, shutil\n",
      "\n",
      "os.chdir('/home/will/HIVTropism//')\n",
      "sys.path.append('/home/will/HIVReportGen/AnalysisCode/')\n",
      "sys.path.append('/home/will/PySeqUtils/')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SeqProcessTools import read_pat_seq_data, load_training_seq_data, align_seq_data_frame\n",
      "from TreeingTools import make_mrbayes_trees, run_bats, get_pairwise_distances, check_distance_pvals\n",
      "from GeneralSeqTools import fasta_reader, WebPSSM_V3_fasta, yield_chunks\n",
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import generic_dna\n",
      "import glob\n",
      "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
      "from itertools import chain"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/futures/__init__.py:24: DeprecationWarning: The futures package has been deprecated. Use the concurrent.futures package instead.\n",
        "  DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def simple_translate(inseq):\n",
      "    seq = Seq(inseq, alphabet=generic_dna)\n",
      "    return seq.translate().tostring()\n",
      "\n",
      "\n",
      "seq_files = glob.glob('LANLdata/*.fasta')\n",
      "seq_data = []\n",
      "for f in seq_files:\n",
      "    sub, prot = f.split(os.sep)[-1].split('-')[:2]\n",
      "    with open(f) as handle:\n",
      "        for name, seq in fasta_reader(handle):\n",
      "            nseq = ''.join(l for l in seq if l.isalpha())\n",
      "            if prot != 'LTR':\n",
      "                nseq = simple_translate(nseq)\n",
      "            seq_data.append((name, sub, prot, nseq))\n",
      "            \n",
      "seq_df = DataFrame(seq_data, columns=['Name', 'Sub', 'Prot', 'Seq'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v3_seqs = [(name, seq) for name, sub, prot, seq in seq_data if prot == 'V3']\n",
      "\n",
      "have_data = []\n",
      "need_data = set([name for name, _ in v3_seqs])\n",
      "count = 0\n",
      "print 'Getting WebPSSM scores'\n",
      "while need_data and count < 5:\n",
      "    count += 1\n",
      "    print len(need_data)\n",
      "    gen = ((name, seq) for name, seq in v3_seqs if name in need_data)\n",
      "    chunks = yield_chunks(gen, 50)\n",
      "    with ThreadPoolExecutor(max_workers = 10) as e:\n",
      "        res = e.map(WebPSSM_V3_fasta, chunks)\n",
      "        have_data += list(chain.from_iterable(res))\n",
      "    need_data -= set(row[0] for row in have_data)\n",
      "            \n",
      "            \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21378\n",
        "2850"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq_df['Prot'].unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array(['Nef', 'gp41', 'gp120', 'LTR', 'V3'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "def safe_float(inval):\n",
      "    try:\n",
      "        return float(inval)\n",
      "    except ValueError:\n",
      "        return np.nan\n",
      "\n",
      "fields = ['name','score','pred','x4.pct','r5.pct','geno','pos.chg','net.chg','percentile']\n",
      "pssm_data = DataFrame(have_data, columns=fields)\n",
      "pssm_data['pred'] = pssm_data['pred'] == '1'\n",
      "\n",
      "float_cols = [1, 3, 4, 6, 7, 8]\n",
      "for col in float_cols:\n",
      "    pssm_data[fields[col]] = pssm_data[fields[col]].map(safe_float)\n",
      "    \n",
      "valid_pssm = pssm_data[pssm_data['percentile']<0.95]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trop_scores = valid_pssm.groupby('name')[['score']].mean()\n",
      "#trop_scores.to_excel('NewPSSMScores.xls')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped_seq_df = seq_df.pivot(index = 'Name', columns='Prot', values='Seq')\n",
      "grouped_seq_df = merge(grouped_seq_df, trop_scores, \n",
      "                        left_index = True, right_index = True)\n",
      "print grouped_seq_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 17742 entries, A37289 to Z95462\n",
        "Data columns (total 6 columns):\n",
        "LTR      62  non-null values\n",
        "Nef      986  non-null values\n",
        "V3       17742  non-null values\n",
        "gp120    2762  non-null values\n",
        "gp41     2425  non-null values\n",
        "score    17742  non-null values\n",
        "dtypes: float64(1), object(5)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def decide_tropism(inval):\n",
      "    if inval < -6.95:\n",
      "        return 'R5'\n",
      "    elif inval > -2.88:\n",
      "        return 'X4'\n",
      "    return np.nan\n",
      "\n",
      "grouped_seq_df['Tropism'] = grouped_seq_df['score'].map(decide_tropism)\n",
      "trops = grouped_seq_df[['Tropism']].dropna()\n",
      "\n",
      "trop_dict = defaultdict(lambda :'R5')\n",
      "for ind, trop in zip(trops.index, trops['Tropism'].values):\n",
      "    trop_dict[ind] = trop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "grouped_seq_df.dropna(subset = ['gp120'])[['score']].to_excel('NewPSSMScores.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_seq_data = grouped_seq_df.dropna(subset = ['gp120'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'aligning'\n",
      "align_data = align_seq_data_frame(wanted_seq_data,  '/home/will/HIVReportGen/Data/BlastDB/ConBseqs.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "align_data['Tropism'] = align_data['score'].map(decide_tropism)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_data = align_data.dropna(subset = ['Tropism'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import product\n",
      "def yield_regions(trop_dict):\n",
      "    \n",
      "    regions = ['gp41-seq-align',\n",
      "               'gp120-seq-align',\n",
      "                'LTR-seq-align',\n",
      "                'Nef-seq-align']\n",
      "    win_sizes = [5,35,10]#,15,20,40,45]\n",
      "    \n",
      "    for region in regions:\n",
      "        prot = region.split('-')[0]\n",
      "        seq_ser = wanted_data[region].dropna()\n",
      "        seqs = [(name, ''.join(list(seq))) for name, seq in zip(seq_ser.index, seq_ser.values)]\n",
      "        seq_len = len(seqs[0][1])\n",
      "        \n",
      "        for win, start in product(win_sizes, range(seq_len)):\n",
      "            stop = start+win\n",
      "            if stop < seq_len:\n",
      "                nseqs = [(name, seq[start:stop]) for name, seq in seqs]\n",
      "                yield prot, start, win, nseqs, trop_dict\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import dendropy\n",
      "import TreeingTools\n",
      "from Bio.Alphabet import generic_dna, generic_protein\n",
      "def calculate_region(arg):\n",
      "    prot, start, win, nseqs, trop_dict = arg\n",
      "    \n",
      "    fname = 'phyliptrees/%s-%i-%i.tree' % (prot, start, win)\n",
      "    \n",
      "    if os.path.exists(fname):\n",
      "        contree = dendropy.Tree.get_from_path(fname, 'nexus')\n",
      "        treeset = dendropy.TreeList.get_from_path(fname + 'set', 'nexus')\n",
      "    else:\n",
      "        \n",
      "        alphabet = generic_protein if prot != 'LTR' else generic_dna\n",
      "        contree = TreeingTools.phylip_tree(nseqs, alphabet=alphabet)\n",
      "        treeset = dendropy.TreeList([contree])\n",
      "        contree.write_to_path(fname, 'nexus')\n",
      "        treeset.write_to_path(fname + 'set', 'nexus')\n",
      "    \n",
      "    \n",
      "    try:\n",
      "        bats_res = TreeingTools.run_bats(treeset, trop_dict, nreps = 1000)\n",
      "    except:\n",
      "        bats_res = None\n",
      "    \n",
      "    try:\n",
      "        dmat = TreeingTools.get_pairwise_distances(contree)\n",
      "        benj_res = TreeingTools.check_distance_pvals(dmat, trop_dict, nreps = 50)\n",
      "    except:\n",
      "        benj_res = None\n",
      "    \n",
      "    return prot, win, start, bats_res, benj_res\n",
      "    \n",
      "        \n",
      "    \n",
      "#prot, start, win, nseqs = regions.next()\n",
      "#tmp = calculate_region(prot, start, win, nseqs, trop_dict)\n",
      "#print tmp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#grouper = itemgetter(0,1)\n",
      "#grouper(tmp)\n",
      "#reload(TreeingTools)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<module 'TreeingTools' from '/home/will/PySeqUtils/TreeingTools.pyc'>"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import groupby, imap\n",
      "from operator import itemgetter\n",
      "from types import StringType\n",
      "from concurrent.futures import ThreadPoolExecutor\n",
      "\n",
      "bats_fields = ['Prot',\n",
      "                 'Start',\n",
      "                 'WinSize',\n",
      "                'null mean',\n",
      "                 'significance',\n",
      "                 'upper 95% CI',\n",
      "                 'observed mean',\n",
      "                 'upper 95% CU',\n",
      "                 'Statistic',\n",
      "                 'lower 95% CI',\n",
      "                 ]\n",
      "benj_fields = ['Prot',\n",
      "                'Start',\n",
      "                'WinSize',\n",
      "                'Group2Mean',\n",
      "                'Group2Std',\n",
      "                'Group2Name',\n",
      "                'Group1Mean',\n",
      "                'Group1Std',\n",
      "                'RawPval',\n",
      "                'AdjPval',\n",
      "                'Group1Name']\n",
      "benj_writer = csv.DictWriter(open('phylip_BenjRes.tsv', 'w'), benj_fields, delimiter = '\\t')\n",
      "bats_writer = csv.DictWriter(open('phylip_BatsRes.tsv', 'w'), bats_fields, delimiter = '\\t')\n",
      "\n",
      "benj_writer.writeheader()\n",
      "bats_writer.writeheader()\n",
      "\n",
      "multi = True\n",
      "print 'Starting multiprocessing!'\n",
      "if multi:\n",
      "    pool = ThreadPoolExecutor(max_workers = 30)\n",
      "    results = pool.map(calculate_region, yield_regions(trop_dict))\n",
      "else:\n",
      "    results = imap(calculate_region, yield_regions(trop_dict))\n",
      "\n",
      "for prot, win, start, bats_res, benj_res in results:\n",
      "    if type(bats_res) == StringType:\n",
      "        print 'eror making tree: ', prot, win, start, bats_res\n",
      "        continue\n",
      "    \n",
      "    tdict = {\n",
      "             'Prot':prot,\n",
      "             'Start':start,\n",
      "             'WinSize':win\n",
      "             }\n",
      "    if benj_res is None:\n",
      "        print 'Error making benj_res at', prot, start, win\n",
      "    else:\n",
      "        benj_res.update(tdict)\n",
      "        benj_writer.writerow(benj_res)\n",
      "    \n",
      "    if bats_res is None:\n",
      "        print 'Error making BATS_res at', prot, start, win\n",
      "        \n",
      "    else:\n",
      "        for row in bats_res:\n",
      "            if None in row:\n",
      "                row.pop(None)\n",
      "            row.update(tdict)\n",
      "            bats_writer.writerow(row)\n",
      "        \n",
      "if multi:\n",
      "    pool.shutdown()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 266, in _feed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    send(obj)\n",
        "PicklingError: Can't pickle <type 'function'>: attribute lookup __builtin__.function failed\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raise KeyError"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{None: [''],\n",
        " 'Prot': 'gp41',\n",
        " 'Start': 0,\n",
        " 'Statistic': 'AI',\n",
        " 'WinSize': 5,\n",
        " 'lower 95% CI': '9.216707229614258',\n",
        " 'null mean': '9.918590545654297',\n",
        " 'observed mean': '9.734611511230469',\n",
        " 'significance': '0.48000001907348633',\n",
        " 'upper 95% CI': '10.771217346191406',\n",
        " 'upper 95% CU': '10.474203109741211'}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dendropy.treecalc import PatristicDistanceMatrix\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from random import shuffle\n",
      "\n",
      "def make_trees(all_seqs, col, start, stop):\n",
      "    \n",
      "    test_seqs = []\n",
      "    for (pid, vn), seq in all_seqs.iterrows():\n",
      "        try:\n",
      "            tseq = ''.join(list(seq[col][start:stop]))\n",
      "        except IndexError:\n",
      "            continue\n",
      "        key = pid+'-'+vn\n",
      "        if (key in trop_dict):\n",
      "            test_seqs.append((key, tseq))\n",
      "    print len(test_seqs)\n",
      "    return make_mrbayes_trees(test_seqs)\n",
      "\n",
      "\n",
      "def get_pairwise_distances(con_tree):\n",
      "   \n",
      "    taxons = con_tree.taxon_set\n",
      "    pdm = PatristicDistanceMatrix(con_tree)\n",
      "    pdm.calc()\n",
      "    dmat = {}\n",
      "    for p1, p2 in combinations(taxons, 2):\n",
      "        d = pdm(p1, p2)\n",
      "        dmat[(p1.label, p2.label)] = d\n",
      "        dmat[(p2.label, p1.label)] = d\n",
      "        \n",
      "    return dmat\n",
      "\n",
      "def check_distance_pvals(mat_data, trop_dict):\n",
      "    nreps = 500\n",
      "    frac = 0.5\n",
      "    g1dist = []\n",
      "    g2dist = []\n",
      "    for (key1, key2), dist in mat_data.items():\n",
      "        if (trop_dict[key1]=='R5') and (trop_dict[key2] == 'R5'):\n",
      "            g1dist.append(dist)\n",
      "        elif (trop_dict[key1] == 'X4') and (trop_dict[key2] == 'X4'):\n",
      "            g2dist.append(dist)\n",
      "    nitems = int(min(frac*len(g1dist), frac*len(g2dist)))\n",
      "    print len(g1dist), len(g2dist)\n",
      "    _, raw_pval = ttest_ind(g1dist, g2dist)\n",
      "    cor_pvals = []\n",
      "    for _ in range(nreps):\n",
      "        shuffle(g1dist)\n",
      "        shuffle(g2dist)\n",
      "        _, pval = ttest_ind(g1dist[:nitems], g2dist[:nitems])\n",
      "        cor_pvals.append(pval)\n",
      "    return raw_pval, np.mean(cor_pvals), np.mean(g1dist), np.mean(g2dist), np.std(g1dist), np.std(g2dist)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from concurrent.futures import ProcessPoolExecutor\n",
      "from itertools import imap\n",
      "import csv\n",
      "\n",
      "def do_analysis(tup):\n",
      "    start, window = tup\n",
      "    stop = start + window\n",
      "    print 'starting process'\n",
      "    con_tree, multi_trees = make_trees(all_seqs[['gp120-seq-align']].dropna(), 'gp120-seq-align', start, stop)\n",
      "    #print con_tree\n",
      "    #print multi_trees\n",
      "    #bats_res = run_bats(multi_trees[:100], trop_dict)\n",
      "    \n",
      "    dmat = get_pairwise_distances(con_tree)\n",
      "    mgd_res = check_distance_pvals(dmat, trop_dict)\n",
      "    \n",
      "    return start, window, mgd_res\n",
      "\n",
      "\n",
      "\n",
      "window = 35\n",
      "final_res = []\n",
      "win = 35\n",
      "inputs = [(start, win) for win in [5,10,15,20] for start in range(0, 462-win)]\n",
      "if not os.path.exists('/home/will/tmpstuf/results.csv'):\n",
      "    with open('/home/will/tmpstuf/results.csv', 'a') as ohandle:\n",
      "        writer = csv.writer(ohandle, delimiter = '\\t')\n",
      "        with ProcessPoolExecutor(max_workers = 20) as ex:\n",
      "            res_list = ex.map(do_analysis, inputs)\n",
      "            #res_list = imap(do_analysis, inputs)\n",
      "            for start, win, mgd_res in res_list:\n",
      "                print start, win, 'finished'\n",
      "                writer.writerow((start, win)+mgd_res)\n",
      "raise KeyError"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = ['Start', 'WinSize', 'RawP', 'AdjP', 'R5Mean', 'X4Mean', 'R5std', 'X4std']\n",
      "final_data = read_csv('/home/will/tmpstuf/results.csv', sep = '\\t', names=headers)\n",
      "\n",
      "final_data['Prot'] = 'gp120'\n",
      "\n",
      "nheaders = ['Prot', 'Start', 'WinSize', 'RawP', 'AdjP', 'R5Mean', 'X4Mean', 'R5std', 'X4std']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#one_based\n",
      "gp120_features = [('V1', 100, 127),\n",
      "                  ('V2', 127, 166),\n",
      "                  ('V3', 266, 301),\n",
      "                  ('V4', 355, 388),\n",
      "                  ('V5', 430, 439)]\n",
      "from matplotlib.patches import Rectangle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_data.head()\n",
      "nfinal_data = final_data.groupby(['WinSize', 'Start']).agg('mean')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize = (10,10))\n",
      "winsizes = sorted(final_data['WinSize'].unique())\n",
      "plt.hold(True)\n",
      "for wsize in winsizes:\n",
      "    df = nfinal_data.ix[wsize].dropna()\n",
      "    yvals = (-np.log10(df['AdjP'])).values\n",
      "    xvals = (df.index + wsize/2).values\n",
      "    plt.plot(xvals, yvals, label = str(wsize))\n",
      "plt.xlabel('Gp120-pos')\n",
      "plt.ylabel('-log10(p-val)')\n",
      "\n",
      "for name, start, stop in gp120_features:\n",
      "    rect = Rectangle([start, 0], stop-start, 350, facecolor = 'r', alpha = 0.2)\n",
      "    plt.gca().add_patch(rect)\n",
      "    plt.text((start+stop)/2, 330, name)\n",
      "    #plt.vlines([start, stop], 0, 300)\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "plt.ylim([0,350])\n",
      "plt.xlim([0, 460])\n",
      "plt.hold(False)\n",
      "plt.savefig('gp120-multi-win.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize = (10,10))\n",
      "\n",
      "plt.hold(True)\n",
      "for wsize in winsizes:\n",
      "    if wsize < 11:\n",
      "        df = nfinal_data.ix[wsize].dropna()\n",
      "        yvals = (-np.log10(df['AdjP'])).values\n",
      "        xvals = (df.index + wsize/2).values\n",
      "        plt.plot(xvals, yvals, label = str(wsize))\n",
      "plt.xlabel('Gp120-pos')\n",
      "plt.ylabel('-log10(p-val)')\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "plt.ylim([0,350])\n",
      "plt.xlim([266, 301])\n",
      "plt.hold(False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smoothed_pvals = rolling_mean(nfinal_data['AdjP'], 10)\n",
      "print smoothed_pvals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas.stats.moments import rolling_mean\n",
      "\n",
      "plt.figure(figsize = (10,10))\n",
      "\n",
      "plt.hold(True)\n",
      "smoothed_pvals = rolling_mean(nfinal_data['AdjP'], 10)\n",
      "\n",
      "for wsize in winsizes:\n",
      "    df = smoothed_pvals.ix[wsize].dropna()\n",
      "    #print wsize, df\n",
      "    yvals = (-np.log10(df)).values\n",
      "    xvals = (df.index + wsize/2).values\n",
      "    plt.plot(xvals, yvals, label = str(wsize))\n",
      "plt.xlabel('Gp120-pos')\n",
      "plt.ylabel('-log10(p-val)')\n",
      "\n",
      "for name, start, stop in gp120_features:\n",
      "    rect = Rectangle([start, 0], stop-start, 25, facecolor = 'r', alpha = 0.2)\n",
      "    plt.gca().add_patch(rect)\n",
      "    #plt.text((start+stop)/2, 330, name)\n",
      "    #plt.vlines([start, stop], 0, 300)\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "plt.ylim([0,25])\n",
      "plt.xlim([0, 460])\n",
      "plt.hold(False)\n",
      "plt.savefig('gp120-multi-smoothed.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('wanted_data.pkl') as handle:\n",
      "    wanted_data = pickle.load(handle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import TreeingTools\n",
      "seq_data = wanted_data['Nef-seq-align'].dropna().map(lambda x: ''.join(x[:30])).to_dict().items()\n",
      "with open('test_nef_seq.phylip', 'w') as handle:\n",
      "    TreeingTools.write_phylip_seqs(seq_data, handle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}