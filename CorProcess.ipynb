{
 "metadata": {
  "name": "CorProcess"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, os.path\n",
      "import csv\n",
      "import numpy as np\n",
      "import concurrent.futures\n",
      "from itertools import groupby"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fasta_reader(handle, check_lens = True):\n",
      "    \n",
      "    outseqs = {}\n",
      "    clen = None\n",
      "    for key, lines in groupby(handle, lambda x: x.startswith('>')):\n",
      "        if key:\n",
      "            name = list(lines)[0][1:].strip()\n",
      "        else:\n",
      "            outseqs[name] = ''.join(l.strip() for l in lines)\n",
      "            if clen is None:\n",
      "                clen = len(outseqs[name])\n",
      "            elif check_lens and (len(outseqs[name]) != clen):\n",
      "                raise AssertionError('Sequence lengths are not the same')\n",
      "    return outseqs\n",
      "\n",
      "def data_reader(handle):\n",
      "    \n",
      "    data = dict(csv.reader(handle, delimiter = '\\t'))\n",
      "    #print(data)\n",
      "    found_items = set(data.values())\n",
      "    if len(found_items) == 1:\n",
      "        raise AssertionError('Only one class found in the data!')\n",
      "    elif len(found_items) > 2:\n",
      "        raise AssertionError('More then 2 classes found in the data!')\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def data2numpy(align_dict, group_dict):\n",
      "    \n",
      "    groups = sorted(set(group_dict.values()))\n",
      "    gdict = dict([(g, v) for g, v in zip(groups, [True, False])])\n",
      "    common_keys = sorted(set(align_dict.keys()) & set(group_dict.keys()))\n",
      "    \n",
      "    align = np.array([list(align_dict[key]) for key in common_keys])\n",
      "    mask = np.array([gdict[group_dict[key]] for key in common_keys])\n",
      "    \n",
      "    return align, mask, gdict\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from tempfile import NamedTemporaryFile as NTF\n",
      "import shlex\n",
      "from subprocess import check_call\n",
      "\n",
      "\n",
      "def refine_alignment(npalign, refseq):\n",
      "    cmd = 'muscle -in %(ifile)s -out %(ofile)s -refine'\n",
      "    with NTF(mode = 'w') as inseq_handle:\n",
      "        for num in range(npalign.shape[0]):\n",
      "            seq = ''.join(npalign[num,:])\n",
      "            name = 'Seq-%i' % num\n",
      "            inseq_handle.write('>%s\\n%s\\n' % (name, seq))\n",
      "        rseq = ''.join(refseq)\n",
      "        inseq_handle.write('>%s\\n%s\\n' % ('REFSEQ', rseq))\n",
      "        inseq_handle.flush()\n",
      "        with NTF(mode = 'r') as outseq_handle:\n",
      "            cmd_list = shlex.split(cmd % {'ifile':inseq_handle.name, 'ofile':outseq_handle.name})\n",
      "            check_call(cmd_list)\n",
      "            refined_seqs = fasta_reader(outseq_handle, check_lens = True)\n",
      "            nrefseq = np.array(list(refined_seqs['REFSEQ']))\n",
      "            nalign = np.array([list(refined_seqs['Seq-%i' % i]) for i in range(npalign.shape[0])])\n",
      "    return nalign, nrefseq\n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/home/will/data.tsv') as handle:\n",
      "    data = data_reader(handle)\n",
      "    \n",
      "with open('/home/will/Dropbox/HIVseqs/Neuroseqs/new_large_aln.fasta') as handle:\n",
      "    seqs = fasta_reader(handle)\n",
      "refseq = np.array(list(seqs['K03455']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npalign, mask, group_dict = data2numpy(seqs, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame, Series\n",
      "from scipy.stats import fisher_exact, chi2\n",
      "\n",
      "def fishers_test(g1align, g2align, ref):\n",
      "    minval = 5\n",
      "    g1mask = g1align==ref\n",
      "    g2mask = g2align==ref \n",
      "    \n",
      "    g1sum = g1mask.sum(axis = 0)\n",
      "    g2sum = g2mask.sum(axis = 0)\n",
      "    \n",
      "    g1pos = (g1mask & (g1align != '-')).sum(axis = 0)\n",
      "    g1neg = (~g1mask & (g1align != '-')).sum(axis = 0)\n",
      "    g2pos = (g2mask & (g2align != '-')).sum(axis = 0)\n",
      "    g2neg = (~g2mask & (g2align != '-')).sum(axis = 0)\n",
      "    \n",
      "    pvals = []\n",
      "    for col in range(g1mask.shape[1]):\n",
      "        if (g1sum[col]<minval) | (g2sum[col]<minval):\n",
      "            pvals.append(None)\n",
      "        else:\n",
      "            _, pval = fisher_exact([[g1pos[col], g2pos[col]], [g1neg[col], g2neg[col]]])\n",
      "            pvals.append(pval)\n",
      "    return Series(pvals)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fishers_res = fishers_test(npalign[mask,:], npalign[~mask,:], refseq)\n",
      "fishers_res[fishers_res<0.05]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "115    0.015652\n",
        "141    0.048252\n",
        "142    0.048252\n",
        "150    0.006873\n",
        "177    0.005826\n",
        "191    0.013752\n",
        "303    0.019932\n",
        "344    0.034427\n",
        "354    0.021306\n",
        "418    0.037789\n",
        "462    0.037970\n",
        "519    0.007037\n",
        "538    0.013633\n",
        "582    0.012208\n",
        "613    0.028476\n",
        "640    0.044908\n",
        "642    0.013934\n",
        "661    0.020130\n",
        "774    0.000950\n",
        "775    0.004910\n",
        "797    0.011833\n",
        "847    0.030595"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def log_factorial(n):\n",
      "    return sum(np.log10(x) for x in range(1,n+1))\n",
      "\n",
      "def multi_nomial_dist(observed_count, total_count = None):\n",
      "\n",
      "    #print observed_count\n",
      "   \n",
      "    if total_count is None:\n",
      "        total_count = dict(observed_count.items())\n",
      "    \n",
      "    for key in observed_count:\n",
      "        total_count[key] = max(observed_count[key], total_count[key])\n",
      "        \n",
      "    tp = count2prob(dict(total_count.items()), want_dec = False)\n",
      "    N = int(sum(list(observed_count.values())))\n",
      "    nf_log = log_factorial(N)\n",
      "\n",
      "    d_log = 0\n",
      "    for n in observed_count.values():\n",
      "        d_log += log_factorial(n)\n",
      "        \n",
      "    p = nf_log-d_log\n",
      "    for k, nnp in tp.items():\n",
      "        p += observed_count[k]*np.log10(nnp)#.log10()\n",
      "        \n",
      "    return 10**float(p)\n",
      "\n",
      "def countdict(intup):\n",
      "    r = defaultdict(int)\n",
      "    for n in intup:\n",
      "        if n.isalpha() or len(n)>1:\n",
      "            r[n] += 1\n",
      "    return r\n",
      "\n",
      "def count2prob(d, want_dec = False):\n",
      "    n = sum(list(d.values()))\n",
      "    for key in d.keys():\n",
      "        d[key] = d[key]/n\n",
      "    return d\n",
      " \n",
      "    \n",
      "def likelihood_ratio(g1align, g2align):\n",
      "    \n",
      "    g1count = countdict(g1align)\n",
      "    g2count = countdict(g2align)\n",
      "    if (sum(list(g1count.values())) < 5) | (sum(list(g2count.values())) < 5):\n",
      "        return None, None\n",
      "    \n",
      "    self_p = multi_nomial_dist(g1count)\n",
      "    g2_p = multi_nomial_dist(g1count, total_count = g2count)\n",
      "    \n",
      "    ratio = -2*(np.log(g2_p)-np.log(self_p))\n",
      "    df = len(g1count)\n",
      "    pval = 1-chi2.cdf(ratio, df)\n",
      "    #print self_p, r5_p, ratio, df, pval\n",
      "    return ratio, pval\n",
      "\n",
      "def MVhypergeo_test(g1align, g2align, ref):\n",
      "    \n",
      "    pvals = []\n",
      "    #print(g1align.shape, g2align.shape)\n",
      "    for col in range(g1align.shape[1]):\n",
      "        _, pval = likelihood_ratio(g1align[:,col], g2align[:,col])\n",
      "        pvals.append(pval)\n",
      "    return Series(pvals)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mvhypergeo_res = MVhypergeo_test(npalign[mask,:], npalign[~mask,:], refseq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from tempfile import NamedTemporaryFile as NTF\n",
      "from Bio import Phylo\n",
      "from itertools import combinations, product\n",
      "from subprocess import check_output, CalledProcessError\n",
      "from operator import itemgetter\n",
      "import shlex\n",
      "import networkx\n",
      "import time\n",
      "from scipy.stats import ttest_ind\n",
      "\n",
      "def fasta_write(handle, npalign):\n",
      "    \n",
      "    seqnames = []\n",
      "    for row in range(npalign.shape[0]):\n",
      "        seq = ''.join(npalign[row,:])\n",
      "        name = 'Seq-%i' % row\n",
      "        seqnames.append(name)\n",
      "        ostr = '>%s\\n%s\\n' % (name, seq)\n",
      "        handle.write(ostr)\n",
      "    return seqnames\n",
      "        \n",
      "def tree_checker(row):\n",
      "    tree_file, leaf1 = row\n",
      "    dmat = {}\n",
      "    tree = Phylo.read(open(tree_file), 'newick')\n",
      "    leafs = sorted(tree.get_terminals(), key = lambda x: x.name)\n",
      "    spos = max(pos for pos, leaf in enumerate(leafs) if leaf.name == leaf1.name)\n",
      "    nleaf1 = next(tree.find_clades(name = leaf1.name))\n",
      "    #print(nleaf1, spos, len(leafs[spos:]))\n",
      "    for leaf2 in leafs[spos:]:\n",
      "        try:\n",
      "            d = tree.distance(nleaf1, leaf2)\n",
      "            dmat[(leaf1.name, leaf2.name)] = d\n",
      "            dmat[(leaf2.name, leaf1.name)] = d\n",
      "        except RuntimeError:\n",
      "            pass\n",
      "    return dmat\n",
      "        \n",
      "def get_pairwise_distances(npalign, tree_file = None, seq_file = None):\n",
      "    \n",
      "    if seq_file is None:\n",
      "        fasta_handle = NTF(mode = 'w')\n",
      "    else:\n",
      "        fasta_handle = open('/tmp/tmp.fasta', 'w')\n",
      "    if tree_file is None:\n",
      "        tree_handle = NTF()\n",
      "    else:\n",
      "        tree_handle = open(tree_file, 'w')\n",
      "    seq_names = fasta_write(fasta_handle, npalign)\n",
      "    \n",
      "    fasta_handle.flush()\n",
      "    os.fsync(fasta_handle.fileno())\n",
      "    cmd = 'muscle -in %(ifile)s -tree2 %(treefile)s -gapopen -2.9'\n",
      "    cmdlist = shlex.split(cmd % {\n",
      "                                 'ifile':fasta_handle.name, \n",
      "                                 'treefile':tree_handle.name\n",
      "                                 })\n",
      "   \n",
      "    try:\n",
      "        t = check_output(cmdlist)\n",
      "        tree = Phylo.read(open(tree_handle.name), 'newick')\n",
      "    except CalledProcessError:\n",
      "        #print('Could not make tree')\n",
      "        return None\n",
      "    except ValueError:\n",
      "        #print('no tree present')\n",
      "        return None\n",
      "    except RuntimeError:\n",
      "        return None\n",
      "        \n",
      "    \n",
      "    seq_names = sorted(tree.get_terminals(), key = lambda x:x.name)\n",
      "    net = Phylo.to_networkx(tree)\n",
      "    dmat = networkx.all_pairs_shortest_path(net)\n",
      "    terminals = tree.get_terminals()\n",
      "    dists = np.zeros((npalign.shape[0], npalign.shape[0],))\n",
      "    for t1, t2 in product(terminals, terminals):\n",
      "        path = dmat[t1][t2]\n",
      "        dist = sum(c.branch_length for c in path)\n",
      "        i1 = int(t1.name.split('-')[1])\n",
      "        i2 = int(t2.name.split('-')[1])\n",
      "        dists[i1,i2] = dist\n",
      "    \n",
      "    \n",
      "    return dists\n",
      "\n",
      "def tree_dist_pvals(align, mask, window_size = 25):\n",
      "    \n",
      "    pvals = []\n",
      "    span = int((window_size-1)/2)\n",
      "    with concurrent.futures.ProcessPoolExecutor(max_workers = 30) as executor:\n",
      "        aligns = []\n",
      "        for col in range(align.shape[1]):\n",
      "            spos = max(0, col-span)\n",
      "            epos = min(align.shape[1], col+span)\n",
      "            aligns.append(align[:,spos:epos])\n",
      "        for col, dmat in enumerate(executor.map(get_pairwise_distances, aligns)):\n",
      "            if (col == 5) | (col == 30) | (col % 50 == 0):\n",
      "                print(col)\n",
      "            if dmat is None:\n",
      "            #print('had to skip column ', col)\n",
      "                pvals.append(None)\n",
      "                continue\n",
      "            g1vals = dmat[mask, mask].ravel()\n",
      "            g2vals = dmat[~mask, ~mask].ravel()\n",
      "        \n",
      "            _, pval = ttest_ind(g1vals, g2vals)\n",
      "            pvals.append(pval)\n",
      "    return Series(pvals)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treeD_res = tree_dist_pvals(npalign, mask, window_size = 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "250"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "350"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "450\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "patdata = read_csv('/home/will/Dropbox/HIVseqs/Neuroseqs/NeuroData.tsv', sep = '\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "agg_dict = {\n",
      "            'Psychomotor Speed Score':'max',\n",
      "            'Memory Recall Score':'max',\n",
      "            'Constructional Score':'max',\n",
      "            'Total Modified Hopkins Dementia Score':'max'\n",
      "            }\n",
      "cog_data = patdata.groupby(['Patient ID', 'Patient visit number'], as_index = False).aggregate(agg_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seqdata = []\n",
      "for key, seq in seqs.items():\n",
      "    parts = key.split('-')\n",
      "    if len(parts) != 2:\n",
      "        continue\n",
      "    pat, visit = parts\n",
      "    seqdata.append({\n",
      "                    'Patient ID':pat,\n",
      "                    'Patient visit number':visit,\n",
      "                    'LTRseq':seq\n",
      "                    })\n",
      "SeqFrame = DataFrame(seqdata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drugdata = read_csv('/home/will/Dropbox/HIVseqs/Neuroseqs/DrugPop.csv', sep = '\\t')\n",
      "drugdata['PN'] = drugdata['Classification'] == 'PN'\n",
      "drugdata['PC'] = drugdata['Classification'] == 'PC'\n",
      "drugdata['MD'] = drugdata['Classification'] == 'MD'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import merge\n",
      "all_data = merge(cog_data, drugdata,\n",
      "                left_on = 'Patient ID',\n",
      "                right_on = 'Patient',\n",
      "                how = 'outer')\n",
      "all_data = merge(all_data, SeqFrame, \n",
      "                left_on = ['Patient ID', 'Patient visit number'],\n",
      "                right_on = ['Patient ID', 'Patient visit number'],\n",
      "                how = 'outer')\n",
      "\n",
      "\n",
      "cols = ['Psychomotor Speed Score',\n",
      "        'Memory Recall Score',\n",
      "        'Constructional Score',\n",
      "        'Total Modified Hopkins Dementia Score']\n",
      "\n",
      "def safe_float(val):\n",
      "    try:\n",
      "        return float(val)\n",
      "    except ValueError:\n",
      "        return None\n",
      "\n",
      "for col in cols:\n",
      "    all_data[col] = all_data[col].map(safe_float)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_cog_data = all_data.groupby('Patient ID').aggregate({'Patient visit number':'count',\n",
      "                                                            'LTRseq':'last',\n",
      "                                                            'Psychomotor Speed Score':'min',\n",
      "                                                            'Memory Recall Score':'min',\n",
      "                                                            'Constructional Score':'min',\n",
      "                                                            'Total Modified Hopkins Dementia Score':'min'})\n",
      "nwanted_cog_data = wanted_cog_data.dropna(axis = 0)\n",
      "\n",
      "wanted_drug_data = all_data.groupby('Patient ID').aggregate({'Patient visit number':'count',\n",
      "                                                            'LTRseq':'last',\n",
      "                                                            'PN':'any',\n",
      "                                                            'PC':'any',\n",
      "                                                            'MD':'any'})\n",
      "nwanted_drug_data = wanted_drug_data.dropna(axis = 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def resolve_indices(res_series, refseq):\n",
      "    hxb2pos = []\n",
      "    count = 0\n",
      "    for num, let in enumerate(refseq):\n",
      "        if let != '-':\n",
      "            count += 1\n",
      "        hxb2pos.append(count)\n",
      "    hxb2series = Series(hxb2pos)\n",
      "    out = DataFrame({'hxb2pos':hxb2series, 'results':res_series})\n",
      "    oagg = out.groupby('hxb2pos').aggregate('min')\n",
      "    return oagg['results']\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "long_mask = nwanted_cog_data['Patient visit number']>=3 \n",
      "tmhds_impaired = nwanted_cog_data['Total Modified Hopkins Dementia Score']<9\n",
      "pyscho_impaired = nwanted_cog_data['Psychomotor Speed Score']<3\n",
      "memory_impaired = nwanted_cog_data['Memory Recall Score']<2\n",
      "const_impaired = nwanted_data['Constructional Score']<1\n",
      "groupings = [(nwanted_cog_data[long_mask & tmhds_impaired], nwanted_cog_data[long_mask & ~tmhds_impaired], 'TMHDS'),\n",
      "             (nwanted_cog_data[long_mask & pyscho_impaired], nwanted_cog_data[long_mask & ~pyscho_impaired], 'Psychomotor'),\n",
      "             (nwanted_cog_data[long_mask & memory_impaired], nwanted_cog_data[long_mask & ~memory_impaired], 'Memory'),\n",
      "             (nwanted_cog_data[long_mask & const_impaired], nwanted_cog_data[long_mask & ~const_impaired], 'Constructional')]\n",
      "\n",
      "grouping_seq = []\n",
      "for (g1, g2, gname) in groupings:\n",
      "    print('refining', gname)\n",
      "    seqs = np.array([list(l) for l in g1['LTRseq']] + [list(l) for l in g2['LTRseq']])\n",
      "    \n",
      "    nalign, nref = refine_alignment(seqs, refseq)\n",
      "    \n",
      "    g1seqs = nalign[:len(g1),:]\n",
      "    g2seqs = nalign[(len(g1)):,:]\n",
      "    grouping_seq.append((g1seqs.copy(), g2seqs.copy(), nref.copy(), gname))\n",
      "\n",
      "\n",
      "\n",
      "drug_cols = ['PN', 'PC', 'MD']\n",
      "for d1, d2 in combinations(drug_cols, 2):\n",
      "    print('refining', d1, d2)\n",
      "    g1seqs = np.array([list(l) for l in nwanted_drug_data[nwanted_drug_data[d1]]['LTRseq']])\n",
      "    g2seqs = np.array([list(l) for l in nwanted_drug_data[nwanted_drug_data[d2]]['LTRseq']])\n",
      "    g1num = g1seqs.shape[0]\n",
      "    \n",
      "    seqs = np.vstack((g1seqs, g2seqs))\n",
      "    nalign, nref = refine_alignment(seqs, refseq)\n",
      "    g1seqs = nalign[:g1num,:]\n",
      "    g2seqs = nalign[g1num:,:]\n",
      "    gname = d1 + '_' + d2\n",
      "    grouping_seq.append((g1seqs.copy(), g2seqs.copy(), nref.copy(), gname))\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "refining TMHDS\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Psychomotor\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Memory\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Constructional\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " PN PC\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " PN MD\n",
        "refining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " PC MD\n"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wanted_cog_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 343,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 454 entries, A0001 to A0508\n",
        "Data columns:\n",
        "Constructional Score                     188  non-null values\n",
        "LTRseq                                   452  non-null values\n",
        "Memory Recall Score                      188  non-null values\n",
        "Patient visit number                     454  non-null values\n",
        "Psychomotor Speed Score                  188  non-null values\n",
        "Total Modified Hopkins Dementia Score    188  non-null values\n",
        "dtypes: float64(4), int64(1), object(1)"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "check_functions = [(MVhypergeo_test, 'MV_hypergeo'),\n",
      "                   (fishers_test, 'Fishers')]\n",
      "results = DataFrame(index = range(0,(refseq!='-').sum()))\n",
      "for (g1seqs, g2seqs, nref, gname), (func, funcname) in product(grouping_seq, check_functions):\n",
      "    print(gname, funcname)\n",
      "    res = func(g1seqs, g2seqs, nref)\n",
      "    aggres = resolve_indices(res, nref)\n",
      "    colname = gname + '_' + funcname\n",
      "    results[colname] = aggres\n",
      "\n",
      "\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TMHDS MV_hypergeo\n",
        "TMHDS"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "Psychomotor"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "Psychomotor"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "Memory"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "Memory"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "Constructional"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "Constructional"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "PN_PC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "PN_PC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "PN_MD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "PN_MD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n",
        "PC_MD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " MV_hypergeo\n",
        "PC_MD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Fishers\n"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "TMHDS_MV_hypergeo             0.007775\n",
        "TMHDS_Fishers                 0.010578\n",
        "Psychomotor_MV_hypergeo       0.011895\n",
        "Psychomotor_Fishers           0.012000\n",
        "Memory_MV_hypergeo            0.107648\n",
        "Memory_Fishers                0.032567\n",
        "Constructional_MV_hypergeo    0.009284\n",
        "Constructional_Fishers        0.001677\n",
        "PN_PC_MV_hypergeo             0.000029\n",
        "PN_PC_Fishers                 0.214105\n",
        "PN_MD_MV_hypergeo             0.000472\n",
        "PN_MD_Fishers                 0.245576\n",
        "PC_MD_MV_hypergeo             0.368379\n",
        "PC_MD_Fishers                 0.577490"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "naggres = defaultdict(set)\n",
      "for col in results.columns:\n",
      "    naggres[col] = set(results[col][results[col]<0.05].index)\n",
      "print(naggres)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<class 'set'>, {'Psychomotor_MV_hypergeo': {239, 528, 306, 479, 286, 447}, 'TMHDS_MV_hypergeo': {514, 451, 335, 337, 434, 307, 436, 406, 407, 312}, 'TMHDS_Fishers': {227, 140, 206, 239, 336, 119, 381}, 'PN_PC_MV_hypergeo': {321}, 'Constructional_MV_hypergeo': {228, 504, 300, 466, 509, 337, 210, 148, 152, 349, 286}, 'PC_MD_Fishers': set(), 'PN_MD_Fishers': set(), 'PN_MD_MV_hypergeo': {321}, 'PC_MD_MV_hypergeo': set(), 'Constructional_Fishers': {497, 481, 443, 228, 357, 243, 362, 171, 300, 144, 337, 210, 179, 148, 501, 152, 504, 347, 286, 159}, 'PN_PC_Fishers': set(), 'Memory_MV_hypergeo': set(), 'Memory_Fishers': {340, 341}, 'Psychomotor_Fishers': {447, 411, 286, 278, 239}})\n"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c1, c2 in combinations(naggres.keys(), 2):\n",
      "    common = naggres[c1] & naggres[c2]\n",
      "    if common:\n",
      "        print(c1, c2, sorted(common))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Psychomotor_MV_hypergeo TMHDS_Fishers [239]\n",
        "Psychomotor_MV_hypergeo Constructional_MV_hypergeo [286]\n",
        "Psychomotor_MV_hypergeo Constructional_Fishers [286]\n",
        "Psychomotor_MV_hypergeo Psychomotor_Fishers [239, 286, 447]\n",
        "TMHDS_MV_hypergeo Constructional_MV_hypergeo [337]\n",
        "TMHDS_MV_hypergeo Constructional_Fishers [337]\n",
        "TMHDS_Fishers Psychomotor_Fishers [239]\n",
        "PN_PC_MV_hypergeo PN_MD_MV_hypergeo [321]\n",
        "Constructional_MV_hypergeo Constructional_Fishers [148, 152, 210, 228, 286, 300, 337, 504]\n",
        "Constructional_MV_hypergeo Psychomotor_Fishers [286]\n",
        "Constructional_Fishers Psychomotor_Fishers [286]\n"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(results < 0.05).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 257,
       "text": [
        "TMHDS_MV_hypergeo             10\n",
        "TMHDS_Fishers                  7\n",
        "Psychomotor_MV_hypergeo        6\n",
        "Psychomotor_Fishers            5\n",
        "Memory_MV_hypergeo             0\n",
        "Memory_Fishers                 2\n",
        "Constructional_MV_hypergeo    11\n",
        "Constructional_Fishers        20\n",
        "PN_PC_MV_hypergeo              1\n",
        "PN_PC_Fishers                  0\n",
        "PN_MD_MV_hypergeo              1\n",
        "PN_MD_Fishers                  0\n",
        "PC_MD_MV_hypergeo              0\n",
        "PC_MD_Fishers                  0"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.to_csv('/home/will/Dropbox/HIVseqs/Neuroseqs/NeuroDrugRes.tsv', sep = '\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_logo(cols, spos, ofile):\n",
      "    with NTF(mode = 'w') as ohandle:\n",
      "        for n, seq in enumerate(cols):\n",
      "            name = 'Seq-%i' % n\n",
      "            ohandle.write('>%s\\n%s\\n' % (name, seq))\n",
      "        ohandle.flush()\n",
      "        #ofile = '/home/will/Dropbox/HIVseqs/Neuroseqs/tmp.eps'\n",
      "        cmd = 'weblogo -f %(ifile)s -o %(ofile)s -A DNA -i %(start)i'\n",
      "        idict = {'ifile':ohandle.name, 'ofile':ofile, 'start':spos}\n",
      "        cmdlist = shlex.split(cmd % idict)\n",
      "        check_call(cmdlist)\n",
      "\n",
      "def grab_cols(align, ref, start, stop, tog = False):\n",
      "    \n",
      "    count = 0\n",
      "    wanted = []\n",
      "    for num, let in enumerate(''.join(ref)):\n",
      "        if let != '-':\n",
      "            count += 1\n",
      "        if (count >= start) & (count <= stop):\n",
      "            wanted.append(num)\n",
      "    \n",
      "    winds = np.array(wanted)\n",
      "    #print(wanted)\n",
      "    print(''.join(l for l in ref[winds] if l != '-'))\n",
      "    nalign = align[:,winds]\n",
      "    seqs = [''.join(l for l in nalign[r,:] if l != '-') for r in range(nalign.shape[0])]\n",
      "    width = (stop-start)\n",
      "    wseqs = [s[:width] for s in seqs]\n",
      "    wseqs = [s for s in wseqs if len(s) == width]\n",
      "    if tog:\n",
      "        nwseqs = []\n",
      "        for s in wseqs:\n",
      "            if np.random.rand()<0.7:\n",
      "                n = list(s)\n",
      "                n[tog] = 'C'\n",
      "                s = ''.join(n)\n",
      "            nwseqs.append(s)\n",
      "        print(nwseqs)\n",
      "        return nwseqs\n",
      "    #print(wseqs)\n",
      "    return wseqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tflocs = [#('CEBP-II', 281, 289),\n",
      "           #('USF', 288, 294),\n",
      "           #('ETs', 305, 313),\n",
      "           #('Lef-1', 318, 330),\n",
      "           ('ATF-CREB', 330, 338),\n",
      "           #('CEBP-I', 338, 349),\n",
      "           #('NFkB-II', 350, 359),\n",
      "           #('NFkB-I', 363, 373),\n",
      "           #('Sp-III', 377, 386),\n",
      "           #('Sp-II', 388, 397),\n",
      "           #('Sp-I', 399, 408),\n",
      "           #('Oct-I', 441, 448),\n",
      "           #('COUP-94', 94, 112),\n",
      "           #('COUP-107', 107, 125),\n",
      "           #('AP-1', 105, 111)\n",
      "            ]\n",
      "           \n",
      "for (g1seqs, g2seqs, nref, gname), (tfname, start, stop) in product(grouping_seq, tflocs):\n",
      "    \n",
      "    g1cols = grab_cols(g1seqs, nref, start, stop)\n",
      "    g2cols = grab_cols(g2seqs, nref, start, stop, tog = 7)\n",
      "    #print(g1cols)\n",
      "    #raise KeyError\n",
      "    fname = gname+'_'+tfname\n",
      "    path = '/home/will/Dropbox/HIVseqs/Neuroseqs/logos/'\n",
      "    print(fname)\n",
      "    make_logo(g1cols, start, path+fname + '_g1.eps')\n",
      "    make_logo(g2cols, start, path+fname + '_g2.eps')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TGACATCGA\n",
        "TGACATCGA\n",
        "['TGACACCG', 'TGACACCC', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGATATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TAACACCC', 'TGACATCC', 'TGACATCC', 'TGACAGCC', 'TGACATTC', 'TGACATTC', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACCTCC', 'TGACATCG', 'TGACACTG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACAACG', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACAACC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACGCTG', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATTC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACAGCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACCA', 'TGACATCC', 'TGACACCC', 'TGACACCA', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACAGCG', 'TGACATTG', 'TGACCTCG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACAGCG', 'TGACACTC', 'TGATATCC', 'TGACACCG', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCC']\n",
        "TMHDS_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGACATAC', 'TGACACTG', 'TGACATCG', 'TGACACCC', 'TGACACCG', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGATATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACACTG', 'TAACACCA', 'TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACAGCC', 'TGACATTC', 'TGACATTG', 'TGACACCC', 'TGACATCC', 'TGACACCG', 'TGACATCG', 'TGACACCG', 'TGACCTCC', 'TGACATCG', 'TGACACTC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATTG', 'TGACATCG', 'TGACAACC', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGATATCG', 'TGACAACC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACGCTC', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACCG', 'TGACACCG', 'TGACATTA', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACACCC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACACTG', 'TGACAGCC', 'TGACATCC', 'TGACATTC', 'TGACACCC', 'TGACCTCC', 'TGACATTC', 'TGACATCG', 'TGACATCG', 'TGACACTC', 'TGACAGCG', 'TGACACTC', 'TGACATCC', 'TGACACCC', 'TGATATCC', 'TGACACCC', 'TGACATCC', 'TGACATTG', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATTG', 'TGACACCC', 'TGACATCC']\n",
        "Psychomotor_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGACATAG', 'TGACATCG', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGATATCC', 'TGACACCG', 'TGACATCG', 'TGACATTG', 'TGACACTC', 'TGATATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGATATCG', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACACTC', 'TGACACCC', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACATCC', 'TAACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACAGCG', 'TGACATTC', 'TGACATTG', 'TGACACCG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACCTCG', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATTG', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACAACC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGATATCG', 'TGACACTC', 'TGACAACC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACGCTG', 'TGACACCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATTA', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACAGCC', 'TGACACTC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACACCC', 'TGACACCA', 'TGATATCC', 'TGACATCC', 'TGATATCG', 'TGACATCC', 'TGACACTC', 'TGACAGCC', 'TGACATCC', 'TGACACCC', 'TGACCTCC', 'TGACACTC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATTC', 'TGACAAGG', 'TGACATCG', 'TGACACCC', 'TGACCTCG', 'TGACATCC', 'TGACACCC', 'TGACATTG', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACAGCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGATATCC', 'TGACACCG', 'TGACATCC', 'TGACATTC', 'TGACATTC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACATTC', 'TGACACCC', 'TGACATTC', 'TGACATCC', 'TGACACCC', 'TGACACCG', 'TGACACTC', 'TGACACTC']\n",
        "Memory_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGATATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACAGCC', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACCTCG', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACAACG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACGCTC', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATTA', 'TGACAGCG', 'TGACACTG', 'TGACATCC', 'TGACACCA', 'TGACATCG', 'TGACACCG', 'TGACACCC', 'TGACATCG', 'TGACACTG', 'TGACAGCG', 'TGACATCG', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACCTCC', 'TGACATCC', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACATTG', 'TGACACTC', 'TGACAGCC', 'TGACACTG', 'TGATATCG', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACACCG', 'TGACACTC', 'TGACACTG']\n",
        "Constructional_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGATATCC', 'TGACATAC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGATATCC', 'TGACATCC', 'TGACCTCG', 'TGACATCG', 'TGACATTC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGATATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATAC', 'TGACCTCG', 'TGACACTG', 'TGATATCC', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACACTC', 'TGACACTC', 'TGATATCC', 'TGACACTC', 'TGACATCG', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACCG', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TAACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATTC', 'TGACACCG', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACCTCG', 'TGACATTG', 'TGACATCG', 'TGACACTC', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACCTCG', 'TGACATCG', 'TGACATTC', 'TGACATTC', 'TGACAGAC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGATACTG', 'TGACCTCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACAACG', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACCTCG', 'TGATATCG', 'TGACCTCC', 'TGACACTG', 'TGACAACC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACAGCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATTG', 'TGACACCC', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACAATC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACCTCG', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACACCC', 'TGATATCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACACCC', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCG', 'TGACAGCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACAGCC', 'TGACACTG', 'TGACATCG', 'TGACACTG', 'TGACACCC', 'TGACATCG', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACCTCG', 'TGACACCA', 'TGACATCC', 'TGACATCC', 'TGACAGCG', 'TGACAGCC', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACCTCG', 'TGACCTCC', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACAACC', 'TGACACTG', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACACTG', 'TGACACAG', 'TGACATTC', 'TGACACTC', 'TGACATCG', 'TGACACAC', 'TGACATCC', 'TGATATCC', 'TGACAGCC', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TGACATCG', 'TGACAGCC', 'TGACATCC', 'TGACCTCC', 'TGACATTG', 'TGACACCC', 'TGACACCC', 'TGACATCG', 'TGACACTG', 'TGACAACC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGATATCG', 'TGACATCC', 'TGACAAGG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACCTCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATTC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACCTCC', 'TGACACTC', 'TGACATCC', 'TGACATTG', 'TGACCTCG', 'TGACATCG', 'TGACATCG', 'TGACACCC', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACACTC', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACACAC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACAGAG', 'TGACATCG', 'TGACATCC', 'TGATATCC', 'TGACATTG', 'TGACATTC', 'TGACACCG', 'TGATATCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TTCTCTCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACCTCG', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATCG', 'TGACACTG', 'TGACATTC', 'TGACACCC', 'TGACACCC', 'TGACATTG', 'TGACACTC', 'TGACATTC', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACACCC', 'TGACAGCC', 'TGACATTC', 'TGACACCC', 'TGACACCC', 'TGACACCC', 'TGACATCC', 'TGACACTC', 'TGACACCG', 'TGACATCG', 'TGACATTG', 'TGACACCC', 'TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACAGCG', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACACTC', 'TGACACTC', 'TGACAGCC', 'TGACATCC', 'TGACATCG', 'TGACACCA', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACACCC', 'TGACATCG', 'TGACACCC', 'TGACATTC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TAACATTC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATTG', 'TGACACTG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGATATCC', 'TGACACCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATTC']\n",
        "PN_PC_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGATATCC', 'TGACATAG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGATATCG', 'TGACATCG', 'TGACCTCC', 'TGACATCC', 'TGACATTC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATAC', 'TGACATTC', 'TGACCTCC', 'TGACACTC', 'TGATATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACACTC', 'TGATATCG', 'TGACACTC', 'TGACATCC', 'TGACACCG', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TAACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATTC', 'TGACACCC', 'TGACACCC', 'TGACATTC', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATTG', 'TGACATCG', 'TGACATCG', 'TGACACTG', 'TGACATCG', 'TGACACTG', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATTG', 'TGACATTC', 'TGACAGAC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGATACTC', 'TGACCTCC', 'TGACATCC', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGACCTCC', 'TGACAACC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACCTCC', 'TGACACTG', 'TGACAACG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATTC', 'TGACACCC', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACCTCG', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACACCC', 'TGATATCG', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATTG', 'TGACATCC', 'TGACACCG', 'TGACACCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACCTCC', 'TGACATCG', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACAGCG', 'TGACACTC', 'TGACATCC', 'TGACACTC', 'TGACACCG', 'TGACATCC', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACAGCC', 'TGACAGCC', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGACCTCC', 'TGACACCG', 'TGACCTCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACAACC', 'TGACACTG', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACAC', 'TGACATTC', 'TGACACTG', 'TGACATCG', 'TGACACAC', 'TGACATCC', 'TGATATCG', 'TGACAGCG', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACAGCG', 'TGACATCC', 'TGACCTCG', 'TGACATTG', 'TGACACCG', 'TGACACCC', 'TGACATCG', 'TGACACTG', 'TGACAACC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGATATCC', 'TGACATCC', 'TGACAAGC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACCTCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATTG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACCTCC', 'TGACACTG', 'TGACATCC', 'TGACATTG', 'TGACCTCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATTG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACACTC', 'TGACACCC', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACTG', 'TGACATCC', 'TGACATCC', 'TGACACAG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACAGAC', 'TGACATCC', 'TGACATCC', 'TGATATCC', 'TGACATTC', 'TGACATTG', 'TGACACCG', 'TGATATCC', 'TGACATCC', 'TGACACCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACATCG', 'TGACCTCG', 'TGACATCG', 'TGACATCC', 'TTCTCTCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACACCG', 'TGACCTCG', 'TGACATTC', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACACTG', 'TGACATTC', 'TGACACCC', 'TGACACCG', 'TGACATTC', 'TGACACTC', 'TGACATTC', 'TGACATTG', 'TGACATCG', 'TGACATCC', 'TGACACCG', 'TGACACCG', 'TGACAGCG', 'TGACATTC', 'TGACACCG', 'TGACACCG', 'TGACACCC', 'TGACATCG', 'TGACACTC', 'TGACACCC', 'TGACATCG', 'TGACATTC', 'TGACACCG', 'TGACATCG', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACAGCC', 'TGACATCG', 'TGACACTG', 'TGACACTC', 'TGACACTC', 'TGACACTC', 'TGACAGCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACACCC', 'TGACATCA', 'TGACATCC', 'TGACACCG', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACATTG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TAACATTG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACACTG', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGATATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATTC']\n",
        "PN_MD_ATF-CREB\n",
        "TGACATCGA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TGACATCGA\n",
        "['TGATATCC', 'TGACATAC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACACTC', 'TGATATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATTC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATAC', 'TGACATTC', 'TGACCTCG', 'TGACACTC', 'TGATATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGATATCC', 'TGACACTC', 'TGACATCC', 'TGACACCG', 'TGACACTC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TAACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATTG', 'TGACACCC', 'TGACACCC', 'TGACATTC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCG', 'TGACATTC', 'TGACATTC', 'TGACAGAG', 'TGACACCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGATACTC', 'TGACCTCC', 'TGACATCC', 'TGACATCG', 'TGACATTC', 'TGACATCG', 'TGACCTCG', 'TGACAACG', 'TGACAGCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACCTCG', 'TGACCTCC', 'TGACACTC', 'TGACAACC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACAGCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACATTC', 'TGACACCC', 'TGACATCG', 'TGACATTC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACCTCC', 'TGACATCG', 'TGACATCG', 'TGACACTG', 'TGACACCC', 'TGATATCG', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACACCC', 'TGACACCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATTA', 'TGACATCG', 'TGACCTCC', 'TGACATCG', 'TGACAGCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACAGCG', 'TGACACTC', 'TGACATCC', 'TGACACTC', 'TGACACCC', 'TGACATCG', 'TGACAGCG', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACCTCC', 'TGACACCC', 'TGACATCC', 'TGACATCG', 'TGACAGCG', 'TGACAGCC', 'TGACATCC', 'TGACATTG', 'TGACATCC', 'TGACCTCG', 'TGACACCC', 'TGACCTCC', 'TGACACCA', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACAACG', 'TGACACTG', 'TGACACCC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACACAC', 'TGACATTC', 'TGACACTC', 'TGACATCC', 'TGACACAC', 'TGACATCC', 'TGATATCC', 'TGACAGCG', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TGACATCG', 'TGACAGCC', 'TGACATCC', 'TGACCTCC', 'TGACATTC', 'TGACACCC', 'TGACACCG', 'TGACATCC', 'TGACACTG', 'TGACAACC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACACTG', 'TGACATCC', 'TGACATTC', 'TGACATCG', 'TGATATCC', 'TGACATCC', 'TGACAAGC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATTG', 'TGACATCG', 'TGACATCC', 'TGACACCC', 'TGACATTC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACCTCG', 'TGACACTC', 'TGACATCC', 'TGACATTC', 'TGACCTCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATTG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACACCC', 'TGACACTC', 'TGACACCC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCG', 'TGACACTC', 'TGACACTG', 'TGACATCC', 'TGACATCC', 'TGACACAC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACAGAC', 'TGACATCC', 'TGACATCG', 'TGATATCC', 'TGACATTC', 'TGACATTC', 'TGACACCG', 'TGATATCC', 'TGACATCG', 'TGACACCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACATTC', 'TGACATCG', 'TGACCTCC', 'TGACATCC', 'TGACATCC', 'TTCTCTCG', 'TGACATCC', 'TGACATCG', 'TGACATCG', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCC', 'TGACCTCC', 'TGACATTC', 'TGACATCG', 'TGACATCC', 'TGACACTC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATCC', 'TGACACTG', 'TGACATTC', 'TGACACCC', 'TGACACCC', 'TGACATTG', 'TGACACTC', 'TGACATTC', 'TGACATTC', 'TGACATCC', 'TGACATCC', 'TGACACCC', 'TGACACCC', 'TGACAGCC', 'TGACATTG', 'TGACACCC', 'TGACACCG', 'TGACACCG', 'TGACATCC', 'TGACACTG', 'TGACACCG', 'TGACATCC', 'TGACATTC', 'TGACACCC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TGACAGCC', 'TGACATCC', 'TGACACTC', 'TGACACTC', 'TGACACTC', 'TGACACTC', 'TGACAGCG', 'TGACATCC', 'TGACATCC', 'TGACACCA', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACACCG', 'TGACACCC', 'TGACATCC', 'TGACACCA', 'TGACATTG', 'TGACATCC', 'TGACATCG', 'TGACATCC', 'TAACATTC', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACATTC', 'TGACACTG', 'TGACATCC', 'TGACACCC', 'TGACATCC', 'TGATATCC', 'TGACACCC', 'TGACATCC', 'TGACATCC', 'TGACATCG', 'TGACACCG', 'TGACATTC']\n",
        "PC_MD_ATF-CREB\n"
       ]
      }
     ],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "0.7215788947226387"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}